{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b930f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge\n",
    "import rospy\n",
    "\n",
    "import pyrealsense2\n",
    "from realsense_depth import *\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import open3d as o3d\n",
    "from open3d_ros_helper import open3d_ros_helper as orh\n",
    "from scipy import spatial\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import math\n",
    "import tf2_ros, tf\n",
    "import geometry_msgs.msg\n",
    "import PyKDL\n",
    "\n",
    "image = None\n",
    "\n",
    "rospy.init_node(\"my_pic\", anonymous=True)\n",
    "\n",
    "tfbuffer = tf2_ros.Buffer()\n",
    "listener = tf2_ros.TransformListener(tfbuffer)\n",
    "br = tf2_ros.TransformBroadcaster()\n",
    "t = geometry_msgs.msg.TransformStamped()\n",
    "\n",
    "bridge = CvBridge()\n",
    "loop_rate = rospy.Rate(0.5) # Node cycle rate (in Hz).\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a31f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_frame():\n",
    "    \n",
    "    frame_color=rospy.wait_for_message('/camera/color/image_raw', Image, timeout=None) #wait_for_message(topic, topic_type, timeout=None): \n",
    "    cv_image_color = bridge.imgmsg_to_cv2(frame_color, desired_encoding='rgb8')\n",
    "    \n",
    "    frame_depth = rospy.wait_for_message('/camera/depth/image_raw', Image, timeout=None) #wait_for_message(topic, topic_type, timeout=None): \n",
    "    cv_image_depth = bridge.imgmsg_to_cv2(frame_depth)\n",
    "    \n",
    "    return cv_image_color, cv_image_depth\n",
    "\n",
    "def visualize_rgbd(rgbd_image):\n",
    "    print(rgbd_image)\n",
    "    #o3d.visualization.draw_geometries([rgbd_image])\n",
    "    \n",
    "    #intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "    #intrinsic.intrinsic_matrix =  [[462.1379699707031, 0.0, 320.0], [0.0, 462.1379699707031, 240.0], [0.0, 0.0, 1.0]]\n",
    "    #intrinsic.intrinsic_matrix =  [[347.99755859375, 0.0, 320.0], [0.0, 347.99755859375, 240.0], [0.0, 0.0, 1.0]]\n",
    "    #intrinsic.intrinsic_matrix =  [[602.71783447, 0.0, 313.06835938], [0.0, 601.61364746, 230.37461853], [0.0, 0.0, 1.0]]\n",
    "    \n",
    "    #w = 640\n",
    "    #h = 480\n",
    "    #fx = 602.71783447\n",
    "    #fy = 601.61364746\n",
    "    #cx = 313.06835938\n",
    "    #cy = 230.37461853\n",
    "    \n",
    "    #Color frame ROS camera\n",
    "    #w = 640\n",
    "    #h = 480\n",
    "    #fx = 462.1379699707031\n",
    "    #fy = 462.1379699707031\n",
    "    #cx = 320.0\n",
    "    #cy = 240.0\n",
    "    \n",
    "    #Depth frame ROS camera\n",
    "    w = 640\n",
    "    h = 480\n",
    "    fx = 347.99755859375\n",
    "    fy = 347.99755859375\n",
    "    cx = 320.0\n",
    "    cy = 240.0    \n",
    "    \n",
    "    \n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic(w, h, fx,fy, cx, cy)\n",
    "    intrinsic.intrinsic_matrix = [[fx, 0, cx], [0, fy, cy], [0, 0, 1]]\n",
    "    \n",
    "    cam = o3d.camera.PinholeCameraParameters()\n",
    "    cam.intrinsic = intrinsic\n",
    "    \n",
    "    #cam.extrinsic = np.array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 1.]])\n",
    "    #pcd = o3d.geometry.create_point_cloud_from_rgbd_image(rgbd_image, cam.intrinsic, cam.extrinsic)\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, cam.intrinsic)\n",
    "    #pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image,intrinsic)\n",
    "    \n",
    "    pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down.\n",
    "    \n",
    "    #o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    return pcd\n",
    "    \n",
    "    \n",
    "def tst_dataset(color_frame,depth_frame):\n",
    "    color_raw = o3d.geometry.Image(np.asarray(color_frame))\n",
    "    depth_raw = o3d.geometry.Image(np.asarray(depth_frame.astype(np.uint16)) )\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, convert_rgb_to_intensity=False)\n",
    "    pcd = visualize_rgbd(rgbd_image)\n",
    "    return pcd\n",
    "\n",
    "\n",
    "def box_pos(x_coord, y_coord, width, height, centered=0):\n",
    "    if centered == 0:\n",
    "        start_point = (x_coord, y_coord) # represents the top left corner of rectangle\n",
    "        end_point = (x_coord+width-1, y_coord+height-1)  # represents the bottom right corner of rectangle\n",
    "    elif centered == 1:\n",
    "        new_x = x_coord - (np.floor(width/2)-1).astype(int)\n",
    "        new_y = y_coord - (np.floor(height/2)-1).astype(int)\n",
    "        start_point = (new_x, new_y) \n",
    "        end_point = (new_x+width, new_y+height)\n",
    "    return start_point, end_point\n",
    "\n",
    "\n",
    "def fetch_transform(tfbuffer,frame1,frame2,quat=0):\n",
    "    flag = 0\n",
    "    while flag==0:\n",
    "        try:\n",
    "            trans = tfbuffer.lookup_transform(frame1, frame2, rospy.Time(),rospy.Duration(8.0))\n",
    "            #print (trans)\n",
    "            trans = trans.transform  #save translation and rotation\n",
    "            #rot = PyKDL.Rotation.Quaternion(* [ trans.rotation.x,trans.rotation.y,trans.rotation.z,trans.rotation.w] )\n",
    "            #ypr = [ i  / np.pi * 180 for i in rot.GetEulerZYX() ]\n",
    "            #print(ypr[2],ypr[1],ypr[0])\n",
    "            \n",
    "            rot = R.from_quat([ trans.rotation.x,trans.rotation.y,trans.rotation.z,trans.rotation.w]) #creates rotation matrix\n",
    "            rpy = rot.as_euler('XYZ',degrees=True) #extrinsic\n",
    "            break\n",
    "        except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException) as e:\n",
    "            #print (\"Fail\", e)\n",
    "            continue\n",
    "    if quat==0:\n",
    "        return trans.translation.x, trans.translation.y, trans.translation.z, rpy[0],rpy[1],rpy[2] #ypr[2], ypr[1], ypr[0]\n",
    "    elif quat==1:\n",
    "        return trans.translation.x, trans.translation.y, trans.translation.z, trans.rotation.x, trans.rotation.y, trans.rotation.z, trans.rotation.w\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def Axis_angle_to_Quat(vector,angle):\n",
    "    x=vector[0]\n",
    "    y=vector[1]\n",
    "    z=vector[2]\n",
    "    qx = x * np.sin(angle/2)\n",
    "    qy = y * np.sin(angle/2)\n",
    "    qz = z * np.sin(angle/2)\n",
    "    qw = np.cos(angle/2)\n",
    "    \n",
    "    return qx,qy,qz,qw\n",
    "\n",
    "def Axis_angle_to_Euler(vector,angle):\n",
    "    x=vector[0]\n",
    "    y=vector[1]\n",
    "    z=vector[2]\n",
    "    s=np.sin(angle)\n",
    "    c=np.cos(angle)\n",
    "    t=1-c\n",
    "    \n",
    "    if ((x*y*t + z*s) > 0.998):  #north pole singularity detected\n",
    "        \n",
    "        heading = 2 * np.arctan2(x*np.sin(angle/2), np.cos(angle/2))\n",
    "        attitude = np.pi/2\n",
    "        bank = 0\n",
    "        return heading, attitude, bank\n",
    "    \n",
    "    elif ((x*y*t + z*s) < -0.998):\n",
    "        \n",
    "        heading = -2 * np.arctan2(x*np.sin(angle/2), np.cos(angle/2))\n",
    "        attitude = -np.pi/2\n",
    "        bank = 0\n",
    "        return heading, attitude, bank\n",
    "    \n",
    "    heading = np.arctan2(y * s- x * z * t , 1 - (y*y+ z*z ) * t)\n",
    "    attitude = np.arcsin(x * y * t + z * s)\n",
    "    bank = np.arctan2(x * s - y * z * t , 1 - (x*x + z*z) * t)\n",
    "    \n",
    "    return bank, heading, attitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e9253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color frame: (480, 640, 3)  Depth frame: (480, 640)\n",
      "Center of image: 217 mm\n",
      "RGBDImage of size \n",
      "Color image : 640x480, with 3 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data.\n",
      "Recompute the normal of the downsampled point cloud\n",
      "Align normals towards camera\n",
      "[   137    138    139 ... 145988 146012 146013]\n",
      "\n",
      "0.0006384502406340135\n",
      "9743\n",
      "\n",
      "Center Coordinates(ground truth): [-0.00380388  0.0008697  -0.21342582]\n",
      "Points Coordinates(estimated center point): [-0.00368968  0.00061495 -0.214     ]\n",
      "Normal Coordinates(Normal of estimated center point): [ 0.70315711 -0.01588428  0.71085706]\n"
     ]
    }
   ],
   "source": [
    "color_frame, depth_frame = grab_frame()\n",
    "print(\"color frame:\",color_frame.shape, \" Depth frame:\",depth_frame.shape)\n",
    "\n",
    "#Check center pixel distance\n",
    "\n",
    "point = (320, 240)\n",
    "\n",
    "#color_frame, depth_frame = grab_frame()\n",
    "\n",
    "distance = depth_frame[point[1], point[0]]\n",
    "print(\"Center of image:\", distance, \"mm\")\n",
    "\n",
    "\n",
    "pt_cloud = tst_dataset(color_frame, depth_frame)\n",
    "\n",
    "downpcd = pt_cloud.voxel_down_sample(voxel_size=0.001)\n",
    "#o3d.visualization.draw_geometries([downpcd])\n",
    "\n",
    "print(\"Recompute the normal of the downsampled point cloud\")\n",
    "downpcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.06, max_nn=30)) #radius in meters\n",
    "print(\"Align normals towards camera\")\n",
    "downpcd.orient_normals_towards_camera_location(camera_location=[0, 0, 0])\n",
    "\n",
    "#o3d.visualization.draw_geometries([downpcd], point_show_normal=True)\n",
    "\n",
    "#v1_normal = np.array(downpcd.normals)\n",
    "#v1_normal_pts = np.array(downpcd.points)\n",
    "\n",
    "#v2_camera = np.array(downpcd.normals)\n",
    "v2_camera_pts = np.array(downpcd.points)\n",
    "\n",
    "\n",
    "\n",
    "#idx = np.where(abs(v2_camera_pts[:,2]) < (distance/1000)+0.01)[0] #fetch all indexes of values less than distance of center of img 0.3 in column 3 of rec\n",
    "idx = np.where(abs(v2_camera_pts[:,2]) < (distance/1000)+0.01)[0] #fetch all indexes of values less than distance of center of img 0.3 in column 3 of rec\n",
    "#idx = np.where(abs(v2_camera_pts[:,2]) < abs(v2_camera_pts[:,2]).max()-0.02)[0] #Remove ground\n",
    "\n",
    "print(idx)\n",
    "filtered_Pt_Cloud = downpcd.select_by_index(idx, invert=False)\n",
    "#o3d.visualization.draw_geometries([filtered_Pt_Cloud], point_show_normal=True)\n",
    "nor = np.array(filtered_Pt_Cloud.normals)\n",
    "pts = np.array(filtered_Pt_Cloud.points)\n",
    "\n",
    "print()\n",
    "distance,index = spatial.KDTree(pts).query( filtered_Pt_Cloud.get_center() ) #find coordinates \n",
    "                                                                             #that are closest to the center \n",
    "\n",
    "print(distance)\n",
    "print(index)\n",
    "print()\n",
    "print(\"Center Coordinates(ground truth):\",filtered_Pt_Cloud.get_center())\n",
    "print(\"Points Coordinates(estimated center point):\",pts[index])\n",
    "print(\"Normal Coordinates(Normal of estimated center point):\",nor[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a00018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be28042a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70315711 -0.01588428  0.71085706] [0. 0. 1.]\n",
      "Z axis-angle angle in degrees 44.69530890918372    axis: [-0.02258418 -0.99974494  0.        ]\n",
      "\n",
      "[ 0.70315711 -0.01588428  0.71085706] [1. 0. 0.]\n",
      "X axis-angle angle in degrees 45.319148263269554    axis: [-0.          0.99975044  0.02233967]\n",
      "\n",
      "[ 0.70315711 -0.01588428  0.71085706] [0. 1. 0.]\n",
      "Y axis-angle angle in degrees 90.91014038950696    axis: [-0.71094676  0.          0.70324584]\n",
      "\n",
      "Rotation wrt camera: Roll: -1.28 Pitch: -44.681 Yaw: 0.526\n",
      "\n",
      "Coordinates wrt camera: [-0.00368968  0.00061495 -0.214     ]\n"
     ]
    }
   ],
   "source": [
    "def getRotation2(v1):\n",
    "    if np.all(v1==[0., 0., 1.]): v1 = [0, 0.000001, 0.999999]\n",
    "    vec_x = [1.,0.,0.] \n",
    "    vec_y = [0.,1.,0.]\n",
    "    vec_z = [0.,0.,1.] #>>>>>>>>>>>>>>>>>>>>> change these to -1 to flip again\n",
    "    \n",
    "    vec1 = v1 / np.linalg.norm(v1)\n",
    "\n",
    "    #vector_x = np.cross(vec1, vec_x)/np.linalg.norm(np.cross(vec1, vec_x))\n",
    "    angle_x = (math.acos(np.dot(vec1, vec_x)))\n",
    "\n",
    "    #vector_y = np.cross(vec1, vec_y)/np.linalg.norm(np.cross(vec1, vec_y))\n",
    "    angle_y = (math.acos(np.dot(vec1, vec_y)))\n",
    "\n",
    "    vector_z = np.cross(vec1, vec_z)/np.linalg.norm(np.cross(vec1, vec_z))\n",
    "    angle_z = (math.acos(np.dot(vec1, vec_z)))\n",
    "\n",
    "    #Rotation = filtered_Pt_Cloud.get_rotation_matrix_from_axis_angle(angle*vector) #alternative Open3D lib.\n",
    "    Rotation = R.from_rotvec(angle_z*vector_z)\n",
    "    \n",
    "    return Rotation, angle_x, angle_y, angle_z\n",
    "\n",
    "rotat, angle_x, angle_y, angle_z = getRotation2(nor[index])\n",
    "\n",
    "flip_frame = R.from_euler('xyz', [0., 180, 0.], degrees=True) \n",
    "#flip_frame2 = R.from_euler('xyz', [0., 0., 180.], degrees=True) #Use if-else to switch between cases\n",
    "#rotat = flip_frame*rotat*flip_frame2  #Use if-else to switch between cases\n",
    "rotat = flip_frame*rotat  #to match correct normal/plane pose (flip later to send to robot)\n",
    "\n",
    "r = rotat.as_euler(\"xyz\", degrees=True)\n",
    "r_quat = rotat.as_quat()            #x,y,z,w format\n",
    "\n",
    "print(\"X axis and normal angle in degrees\",np.degrees(angle_x))\n",
    "print()\n",
    "print(\"Y axis and normal angle in degrees\",np.degrees(angle_y))\n",
    "print()\n",
    "print(\"Z axis and normal angle in degrees\",np.degrees(angle_z))\n",
    "print()\n",
    "\n",
    "print(\"Rotation wrt camera:\",\"Roll:\", np.round(r[0],3), \"Pitch:\", np.round(r[1],3), \"Yaw:\", np.round(r[2],3))\n",
    "#print(\"In Quaternion form xyzw:\",r_quat)\n",
    "print()\n",
    "print(\"Coordinates wrt camera:\",pts[index])\n",
    "\n",
    "t.header.frame_id = \"camera_depth_optical_frame\"\n",
    "t.child_frame_id = \"plane\"\n",
    "\n",
    "t.header.stamp = rospy.Time.now()\n",
    "t.transform.translation.x = pts[index][0]\n",
    "t.transform.translation.y = pts[index][1]\n",
    "t.transform.translation.z = -pts[index][2] #becaues z in opposite dirn\n",
    "\n",
    "#r_quat = tf.transformations.quaternion_from_euler(Roll,Pitch,Yaw)\n",
    "\n",
    "t.transform.rotation.x = r_quat[0]\n",
    "t.transform.rotation.y = r_quat[1]\n",
    "t.transform.rotation.z = r_quat[2]\n",
    "t.transform.rotation.w = r_quat[3]\n",
    "\n",
    "br.sendTransform(t)\n",
    "\n",
    "#transform_plane = fetch_transform(tfbuffer,'world', 'plane',quat=0)\n",
    "\n",
    "#transform_plane = np.round(transform_plane,3)\n",
    "#print()\n",
    "#print(\"Trans XYZ:                            \",transform_plane[0], transform_plane[1], transform_plane[2])\n",
    "#print(\"Rot in world coordinate system (deg):\",transform_plane[3],transform_plane[4],transform_plane[5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e69425b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_plane = fetch_transform(tfbuffer,'world', 'camera_depth_optical_frame',quat=0)\n",
    "\n",
    "transform_plane = np.round(transform_plane,3)\n",
    "print()\n",
    "print(\"Trans XYZ:                            \",transform_plane[0], transform_plane[1], transform_plane[2])\n",
    "print(\"Rot in world coordinate system (deg):\",transform_plane[3],transform_plane[4],transform_plane[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41bd72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesh with coordinate\n",
    "mesh = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1,origin=[0, 0, 0])\n",
    "o3d.visualization.draw_geometries([filtered_Pt_Cloud,mesh], point_show_normal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "za = filtered_Pt_Cloud.get_axis_aligned_bounding_box()\n",
    "za"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "za.get_extent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d0004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3106d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5adc31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "eac38db4",
   "metadata": {},
   "source": [
    "print('Angle: 0')\n",
    "print()\n",
    "print('Positive X count:', np.sum(np.array(nor[:,0]) >= 0, axis=0), \n",
    "      '  Positive Y count:',np.sum(np.array(nor[:,1]) >= 0, axis=0), \n",
    "      '  Positive Z count:',np.sum(np.array(nor[:,2]) >= 0, axis=0), '     Out of:',len(nor[:,0]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dea6a807",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"Estimated angle between Normal and Camera\")\n",
    "print()\n",
    "arr = np.array([])\n",
    "for i in range(len(nor)):\n",
    "    arr = np.append(arr, [np.round(np.degrees(angle_between((0,0,1), nor[i])))])\n",
    "    print(i+1,\" \", np.round(np.degrees(angle_between((0,0,1), nor[i]))) )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8ffe004",
   "metadata": {},
   "source": [
    "arr.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5698aee",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "hi=np.histogram(arr,bins=10)\n",
    "np.set_printoptions(suppress=True)\n",
    "plt.hist(arr,bins=10)\n",
    "plt.title(\"Angle Distribution of depth Image\")\n",
    "plt.show()\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8467a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "92ef1e99",
   "metadata": {},
   "source": [
    "header: \n",
    "  seq: 48630\n",
    "  stamp: \n",
    "    secs: 4484\n",
    "    nsecs: 577000000\n",
    "  frame_id: \"camera_depth_optical_frame\"\n",
    "height: 480\n",
    "width: 640\n",
    "distortion_model: \"plumb_bob\"\n",
    "D: []\n",
    "K: [347.99755859375, 0.0, 320.0, 0.0, 347.99755859375, 240.0, 0.0, 0.0, 1.0]\n",
    "R: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "P: [347.99755859375, 0.0, 320.0, 0.0, 0.0, 347.99755859375, 240.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
    "binning_x: 0\n",
    "binning_y: 0\n",
    "roi: \n",
    "  x_offset: 0\n",
    "  y_offset: 0\n",
    "  height: 0\n",
    "  width: 0\n",
    "  do_rectify: False\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a40ae",
   "metadata": {},
   "source": [
    "\n",
    "start_point,end_point = box_pos(320, 240, 10, 10, centered=1)  #x,y,width,height, 0-- top left coord, 1--- center coord\n",
    "\n",
    "cf = color_frame\n",
    "for i in range (color_frame.shape[0]):\n",
    "    for j in range (color_frame.shape[1]):\n",
    "        if depth_frame[i][j] == 0:\n",
    "            cf[i][j] = [0 , 0, 0] \n",
    "\n",
    "plt.imshow(cf)\n",
    "plt.show()\n",
    "window_name = 'Filtered_image'  # Window name in which image is displayed\n",
    "\n",
    "cv2.rectangle(cf, start_point, end_point, (0, 0, 255), 1)\n",
    "cv2.imshow(window_name, cf)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae4c9e",
   "metadata": {},
   "source": [
    "#color_frame_crop = cf[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "\n",
    "color_frame_crop = cf[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "depth_frame_crop = depth_frame[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "\n",
    "print(depth_frame_crop.shape)\n",
    "zz=depth_frame_crop.T\n",
    "print(zz.shape)\n",
    "\n",
    "#cv2.imshow(\"cropped\", depth_frame_crop)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
