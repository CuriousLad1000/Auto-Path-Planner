{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b930f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge\n",
    "import rospy\n",
    "\n",
    "import pyrealsense2\n",
    "from realsense_depth import *\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import open3d as o3d\n",
    "#import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image = None\n",
    "\n",
    "rospy.init_node(\"my_pic\", anonymous=True)\n",
    "bridge = CvBridge()\n",
    "loop_rate = rospy.Rate(0.5) # Node cycle rate (in Hz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de15c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "def grab_frame():\n",
    "    \n",
    "    frame_color=rospy.wait_for_message('/camera/color/image_raw', Image, timeout=None) #wait_for_message(topic, topic_type, timeout=None): \n",
    "    cv_image_color = bridge.imgmsg_to_cv2(frame_color, desired_encoding='rgb8')\n",
    "    \n",
    "    frame_depth = rospy.wait_for_message('/camera/depth/image_raw', Image, timeout=None) #wait_for_message(topic, topic_type, timeout=None): \n",
    "    cv_image_depth = bridge.imgmsg_to_cv2(frame_depth)\n",
    "    \n",
    "    return cv_image_color, cv_image_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a31f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_rgbd(rgbd_image):\n",
    "    print(rgbd_image)\n",
    "    o3d.visualization.draw_geometries([rgbd_image])\n",
    "    \n",
    "    #intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "    #intrinsic.intrinsic_matrix =  [[462.1379699707031, 0.0, 320.0], [0.0, 462.1379699707031, 240.0], [0.0, 0.0, 1.0]]\n",
    "    #intrinsic.intrinsic_matrix =  [[347.99755859375, 0.0, 320.0], [0.0, 347.99755859375, 240.0], [0.0, 0.0, 1.0]]\n",
    "    #intrinsic.intrinsic_matrix =  [[602.71783447, 0.0, 313.06835938], [0.0, 601.61364746, 230.37461853], [0.0, 0.0, 1.0]]\n",
    "    \n",
    "    #w = 640\n",
    "    #h = 480\n",
    "    #fx = 602.71783447\n",
    "    #fy = 601.61364746\n",
    "    #cx = 313.06835938\n",
    "    #cy = 230.37461853\n",
    "    \n",
    "    #Color frame ROS camera\n",
    "    w = 640\n",
    "    h = 480\n",
    "    fx = 462.1379699707031\n",
    "    fy = 462.1379699707031\n",
    "    cx = 320.0\n",
    "    cy = 240.0\n",
    "    \n",
    "    #Depth frame ROS camera\n",
    "    #w = 640\n",
    "    #h = 480\n",
    "    #fx = 347.99755859375\n",
    "    #fy = 347.99755859375\n",
    "    #cx = 320.0\n",
    "    #cy = 240.0    \n",
    "    \n",
    "    \n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic(w, h, fx,fy, cx, cy)\n",
    "    intrinsic.intrinsic_matrix = [[fx, 0, cx], [0, fy, cy], [0, 0, 1]]\n",
    "    \n",
    "    cam = o3d.camera.PinholeCameraParameters()\n",
    "    cam.intrinsic = intrinsic\n",
    "    \n",
    "    #cam.extrinsic = np.array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 1.]])\n",
    "    #pcd = o3d.geometry.create_point_cloud_from_rgbd_image(rgbd_image, cam.intrinsic, cam.extrinsic)\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, cam.intrinsic)\n",
    "    #pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image,intrinsic)\n",
    "    \n",
    "    pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down.\n",
    "    \n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "    \n",
    "    return pcd\n",
    "    \n",
    "    \n",
    "def tst_dataset(color_frame,depth_frame):\n",
    "    color_raw = o3d.geometry.Image(np.asarray(color_frame))\n",
    "    depth_raw = o3d.geometry.Image(np.asarray(depth_frame.astype(np.uint16)) )\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, convert_rgb_to_intensity=False)\n",
    "    pcd = visualize_rgbd(rgbd_image)\n",
    "    return pcd\n",
    "\n",
    "\n",
    "def box_pos(x_coord, y_coord, width, height, centered=0):\n",
    "    if centered == 0:\n",
    "        start_point = (x_coord, y_coord) # represents the top left corner of rectangle\n",
    "        end_point = (x_coord+width-1, y_coord+height-1)  # represents the bottom right corner of rectangle\n",
    "    elif centered == 1:\n",
    "        new_x = x_coord - (np.floor(width/2)-1).astype(int)\n",
    "        new_y = y_coord - (np.floor(height/2)-1).astype(int)\n",
    "        start_point = (new_x, new_y) \n",
    "        end_point = (new_x+width, new_y+height)\n",
    "    return start_point, end_point\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c799185b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color frame: (480, 640, 3)  Depth frame: (480, 640)\n",
      "Center of image: 291 mm\n"
     ]
    }
   ],
   "source": [
    "color_frame, depth_frame = grab_frame()\n",
    "print(\"color frame:\",color_frame.shape, \" Depth frame:\",depth_frame.shape)\n",
    "\n",
    "#Check center pixel distance\n",
    "\n",
    "point = (320, 240)\n",
    "\n",
    "#color_frame, depth_frame = grab_frame()\n",
    "\n",
    "distance = depth_frame[point[1], point[0]]\n",
    "print(\"Center of image:\", distance, \"mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a40ae",
   "metadata": {},
   "source": [
    "\n",
    "start_point,end_point = box_pos(320, 240, 10, 10, centered=1)  #x,y,width,height, 0-- top left coord, 1--- center coord\n",
    "\n",
    "cf = color_frame\n",
    "for i in range (color_frame.shape[0]):\n",
    "    for j in range (color_frame.shape[1]):\n",
    "        if depth_frame[i][j] == 0:\n",
    "            cf[i][j] = [0 , 0, 0] \n",
    "\n",
    "plt.imshow(cf)\n",
    "plt.show()\n",
    "window_name = 'Filtered_image'  # Window name in which image is displayed\n",
    "\n",
    "cv2.rectangle(cf, start_point, end_point, (0, 0, 255), 1)\n",
    "cv2.imshow(window_name, cf)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae4c9e",
   "metadata": {},
   "source": [
    "#color_frame_crop = cf[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "\n",
    "color_frame_crop = cf[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "depth_frame_crop = depth_frame[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "\n",
    "print(depth_frame_crop.shape)\n",
    "zz=depth_frame_crop.T\n",
    "print(zz.shape)\n",
    "\n",
    "#cv2.imshow(\"cropped\", depth_frame_crop)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2afe395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGBDImage of size \n",
      "Color image : 640x480, with 3 channels.\n",
      "Depth image : 640x480, with 1 channels.\n",
      "Use numpy.asarray to access buffer data.\n"
     ]
    }
   ],
   "source": [
    "pt_cloud = tst_dataset(color_frame, depth_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae8434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdac78c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompute the normal of the downsampled point cloud\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downpcd = pt_cloud.voxel_down_sample(voxel_size=0.2)\n",
    "#o3d.visualization.draw_geometries([downpcd])\n",
    "\n",
    "print(\"Recompute the normal of the downsampled point cloud\")\n",
    "downpcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.01, max_nn=30)) #radius in meters\n",
    "\n",
    "#o3d.visualization.draw_geometries([downpcd], point_show_normal=True)\n",
    "\n",
    "v1_normal = np.array(np.asarray(downpcd.normals))\n",
    "v1_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a205e1bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align normals towards camera\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Align normals towards camera\") #orient_normals_towards_camera_location(self, camera_location=array([0.0, 0.0, 0.0]))\n",
    "\n",
    "downpcd.orient_normals_towards_camera_location()\n",
    "\n",
    "o3d.visualization.draw_geometries([downpcd], point_show_normal=True)\n",
    "\n",
    "v2_camera = np.array(np.asarray(downpcd.normals))\n",
    "v2_camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5274384e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec = np.array(downpcd.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86cf4177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09714215, -0.22224315, -0.43535662],\n",
       "       [-0.26622851,  0.14754292, -0.45154966],\n",
       "       [-0.07836239,  0.10525681, -0.28782354],\n",
       "       [ 0.06675173, -0.14658677, -0.29903121],\n",
       "       [-0.26781304, -0.03859936, -0.45614777],\n",
       "       [-0.21766147,  0.15068299, -0.45154173],\n",
       "       [-0.07856745, -0.14345716, -0.294     ],\n",
       "       [ 0.07195043,  0.10531638, -0.28800668],\n",
       "       [ 0.28411573,  0.1474998 , -0.45226581],\n",
       "       [ 0.28165801, -0.19269493, -0.46075358],\n",
       "       [ 0.07182835, -0.03820167, -0.29156583],\n",
       "       [ 0.28570682, -0.03895756, -0.45690802],\n",
       "       [-0.21763339, -0.03689262, -0.45615721],\n",
       "       [-0.26904887, -0.18872241, -0.45989389],\n",
       "       [-0.07850997, -0.03810011, -0.29135889],\n",
       "       [-0.13769084, -0.22291574, -0.45340192]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.303, 0.017, 0.456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f6faa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zz=downpcd.select_by_index([2,3,6,7,10,14], invert=False)\n",
    "zz=downpcd.select_by_index([10,14], invert=False)\n",
    "o3d.visualization.draw_geometries([zz], point_show_normal=True)\n",
    "nor = np.array(zz.normals)\n",
    "pts = np.array(zz.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25c041ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfa9f289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07182835, -0.03820167, -0.29156583],\n",
       "       [-0.07850997, -0.03810011, -0.29135889]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e76e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"angle between Normal and Camera\")\n",
    "print()\n",
    "for i in range(len(v1_normal)):\n",
    "    print(i+1,\" \", np.round(np.degrees(angle_between(v1_normal[i], v2_camera[i]))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4a492",
   "metadata": {},
   "source": [
    "print(\"Align normals towards tangent plane\") \n",
    "\n",
    "downpcd.orient_normals_consistent_tangent_plane(10)\n",
    "#o3d.visualization.draw_geometries([downpcd], point_show_normal=True)\n",
    "\n",
    "v3_tangent = np.array(np.asarray(downpcd.normals))\n",
    "v3_tangent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b344c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(\"angle between Normal and Camera,   Normal and Tangent\")\n",
    "#print()\n",
    "#for i in range(len(v1_normal)):\n",
    "#    print(i+1,\" \", np.round(np.degrees(angle_between(v1_normal[i], v2_camera[i]))),\"                            \", \n",
    "#               np.round(np.degrees(angle_between(v1_normal[i], v3_tangent[i]))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39276d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024ebcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz1 = downpcd.detect_planar_patches(normal_variance_threshold_deg=60, coplanarity_deg=75, outlier_ratio=0.75, \n",
    "                                   min_plane_edge_length=0.0, min_num_points=0, \n",
    "                                   search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.01, max_nn=30))\n",
    "zz1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9780865",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz2 = downpcd.detect_planar_patches(normal_variance_threshold_deg=60, coplanarity_deg=75, outlier_ratio=0.75, \n",
    "                                   min_plane_edge_length=0.0, min_num_points=0, \n",
    "                                   search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.01, max_nn=30))\n",
    "zz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb989c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f128b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.degrees(angle_between(zz1[0].center, zz2[0].center)))\n",
    "print(np.degrees(angle_between(zz1[1].center, zz2[1].center)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef83140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78df5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837d0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f6706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b83d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#color_frame, depth_frame = grab_frame()\n",
    "df = np.asarray(depth_frame).flatten()\n",
    "hi=np.histogram(df,bins=100)\n",
    "#print(hi[0].shape)\n",
    "#print(hi[1].shape)\n",
    "\n",
    "#plt.hist(df,bins=1800)\n",
    "#plt.title(\"Distance Distribution of depth Image\")\n",
    "#plt.show()\n",
    "unique, counts = np.unique(df, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963362db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth_frame)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_pos(x_coord, y_coord, width, height, centered=0):\n",
    "    if centered == 0:\n",
    "        start_point = (x_coord, y_coord) # represents the top left corner of rectangle\n",
    "        end_point = (x_coord+width-1, y_coord+height-1)  # represents the bottom right corner of rectangle\n",
    "    elif centered == 1:\n",
    "        new_x = x_coord - (np.floor(width/2)-1).astype(int)\n",
    "        new_y = y_coord - (np.floor(height/2)-1).astype(int)\n",
    "        start_point = (new_x, new_y) \n",
    "        end_point = (new_x+width, new_y+height)\n",
    "    return start_point, end_point\n",
    "\n",
    "start_point,end_point = box_pos(320, 240, 300, 300, centered=1)  #x,y,width,height, 0-- top left coord, 1--- center coord\n",
    "\n",
    "cf = color_frame\n",
    "for i in range (color_frame.shape[0]):\n",
    "    for j in range (color_frame.shape[1]):\n",
    "        if depth_frame[i][j] == 0:\n",
    "            cf[i][j] = [0 , 0, 0] \n",
    "\n",
    "plt.imshow(cf)\n",
    "plt.show()\n",
    "window_name = 'Filtered_image'  # Window name in which image is displayed\n",
    "\n",
    "cv2.rectangle(cf, start_point, end_point, (0, 0, 255), 1)\n",
    "cv2.imshow(window_name, cf)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_crop_img = cf[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "crop_img = depth_frame[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "\n",
    "print(crop_img.shape)\n",
    "zz=crop_img.T\n",
    "print(zz.shape)\n",
    "\n",
    "#cv2.imshow(\"cropped\", crop_img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc4ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "li_FB=[]\n",
    "for i in range(crop_img.shape[0]):\n",
    "    ci = crop_img[i][crop_img[i]!=0] #filter out 0 values (mostly errors)\n",
    "    if len(ci)!=0:\n",
    "        li_FB.append(round(np.mean(ci))) \n",
    "print(li_FB)\n",
    "print()\n",
    "\n",
    "li_LR=[]\n",
    "for i in range(crop_img.shape[1]):\n",
    "    ci = zz[i][zz[i]!=0] #filter out 0 values (mostly errors)\n",
    "    if len(ci)!=0:\n",
    "        li_LR.append(round(np.mean(ci))) \n",
    "print(li_LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698e7c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_res(dat_list, max_steps_blocked, outlier_threshold):\n",
    "    dat_list=np.asarray(dat_list)\n",
    "    unique, counts = np.unique(dat_list, return_counts=True)\n",
    "    #print(np.asarray((unique, counts)).T)\n",
    "    if len(unique) < max_steps_blocked:\n",
    "        for i in range(len(counts)):\n",
    "            if counts[i] < outlier_threshold: #if less than threshold, then filter out the result\n",
    "                dat_list = np.delete(dat_list, np.where(dat_list == unique[i]))\n",
    "    return dat_list\n",
    "\n",
    "\n",
    "\n",
    "#filter_res(li_FB,10,10) #list, max blocked steps(adjust this if window size is reduced from 300x300),\n",
    "                     #outlier threshold,if more than this value, then its no longer outlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5b603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh = 0\n",
    "#data_FB = np.asarray(li_FB)\n",
    "#data_LR = np.asarray(li)\n",
    "data_FB = filter_res(li_FB,10,10)\n",
    "data_LR = filter_res(li_LR,10,10)\n",
    "\n",
    "Diff_FB = data_FB[0] - data_FB[-1]\n",
    "Diff_LR = data_LR[0] - data_LR[-1]\n",
    "\n",
    "print(\"Pitch (Front Back)\")\n",
    "print(data_FB[0], data_FB[-1])\n",
    "print(\"Difference FB:\", Diff_FB)\n",
    "print()\n",
    "\n",
    "print(\"Roll (Left Right)\")\n",
    "print(data_LR[0], data_LR[-1])\n",
    "print(\"Difference LR:\", Diff_LR)\n",
    "print()\n",
    "print()\n",
    "\n",
    "if abs(Diff_FB) < 10 and abs(Diff_LR) < 10:\n",
    "    print(\"Surface is Flat!!\")\n",
    "\n",
    "elif abs(Diff_FB) < 10 and Diff_LR > thresh:\n",
    "    print(\"Surface is tilting towards Left\")\n",
    "elif abs(Diff_FB) < 10 and Diff_LR < thresh:\n",
    "    print(\"Surface is tilting towards Right\")\n",
    "\n",
    "elif abs(Diff_LR) < 10 and Diff_FB > thresh:\n",
    "    print(\"Surface is tilting towards Front\")\n",
    "elif abs(Diff_LR) < 10 and Diff_FB < thresh:\n",
    "    print(\"Surface is tilting towards Back\")\n",
    "\n",
    "elif Diff_FB > thresh and Diff_LR < thresh:\n",
    "    print(\"Surface is tilting towards Front right\")\n",
    "elif Diff_FB < thresh and Diff_LR < thresh:\n",
    "    print(\"Surface is tilting towards Back right\")\n",
    "elif Diff_FB > thresh and Diff_LR > thresh:\n",
    "    print(\"Surface is tilting towards Front left\")\n",
    "elif Diff_FB < thresh and Diff_LR > thresh:\n",
    "    print(\"Surface is tilting towards Back left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daffb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pitch (Front Back)\n",
    "idx=np.floor(len(data_FB)/2).astype(int)\n",
    "if len(data_FB)%2 == 1:\n",
    "    xx_fb=np.arange(-idx,idx+1)\n",
    "else:\n",
    "    xx_fb=np.arange(-idx,idx)\n",
    "\n",
    "#Roll (Left Right)\n",
    "idx=np.floor(len(data_LR)/2).astype(int)\n",
    "if len(data_LR)%2 == 1:\n",
    "    xx_lr=np.arange(-idx,idx+1)\n",
    "else:\n",
    "    xx_lr=np.arange(-idx,idx)    \n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(14, 4))\n",
    "ax1.set_title('centered data Roll (L-R)')\n",
    "ax1.plot(xx_lr, data_LR,\"ob\") \n",
    "\n",
    "ax2.set_title('centered data Pitch (F-B)')\n",
    "a=ax2.plot(xx_fb, data_FB,\"ob\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb460b7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mn = np.mean(crop_img[crop_img!=0])\n",
    "#print(mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd5dcfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aca646e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f357c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
