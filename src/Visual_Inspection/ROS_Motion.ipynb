{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b930f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Printing robot current Joint values\n",
      "In Degrees:  [  -0.01056111  -44.85081501    0.00934041 -135.23826566   -0.01893858\n",
      "   89.85587847   45.00280127]\n",
      "\n",
      "============ Printing robot current pose\n",
      "header: \n",
      "  seq: 0\n",
      "  stamp: \n",
      "    secs: 2425\n",
      "    nsecs:   1000000\n",
      "  frame_id: \"world\"\n",
      "pose: \n",
      "  position: \n",
      "    x: 0.3071791097877493\n",
      "    y: 7.302316087318123e-05\n",
      "    z: 0.5873017719057154\n",
      "  orientation: \n",
      "    x: 0.923909386683293\n",
      "    y: -0.382583108972439\n",
      "    z: -0.004204011808465989\n",
      "    w: 0.00198398896125949\n",
      "\n",
      "============ Printing robot current RPY\n",
      "RPY In Degrees:  [179.60548028   0.35787523 -44.98820113]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import rospy\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "#import open3d as o3d\n",
    "from scipy import spatial\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import math\n",
    "import tf2_ros, tf\n",
    "import geometry_msgs.msg\n",
    "import PyKDL\n",
    "import time\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "from moveit_commander.conversions import pose_to_list\n",
    "\n",
    "image = None\n",
    "\n",
    "moveit_commander.roscpp_initialize(sys.argv)\n",
    "rospy.init_node(\"my_motion\", anonymous=True)\n",
    "\n",
    "robot = moveit_commander.RobotCommander()\n",
    "scene = moveit_commander.PlanningSceneInterface()\n",
    "group_name = \"panda_arm\"\n",
    "move_group = moveit_commander.MoveGroupCommander(group_name) #we'll pass it on while calling functions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tfbuffer = tf2_ros.Buffer()\n",
    "listener = tf2_ros.TransformListener(tfbuffer)\n",
    "br = tf2_ros.TransformBroadcaster()\n",
    "t = geometry_msgs.msg.TransformStamped()\n",
    "static_br = tf2_ros.StaticTransformBroadcaster()\n",
    "static_t = geometry_msgs.msg.TransformStamped()\n",
    "\n",
    "loop_rate = rospy.Rate(0.5) # Node cycle rate (in Hz).\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "## Create a `DisplayTrajectory`_ ROS publisher which is used to display\n",
    "## trajectories in Rviz:\n",
    "display_trajectory_publisher = rospy.Publisher(\"/move_group/display_planned_path\", moveit_msgs.msg.DisplayTrajectory, queue_size=20,)\n",
    "\n",
    "\n",
    "print(\"============ Printing robot current Joint values\") #O/P: current joint values of the end-effector\n",
    "#print(move_group.get_current_joint_values())\n",
    "print(\"In Degrees: \", np.degrees( move_group.get_current_joint_values() ) ) #O/P joint angles in degrees\n",
    "print(\"\")\n",
    "\n",
    "print(\"============ Printing robot current pose\") #O/P will be XYZ and xyz w  positions and orientations of the robot.\n",
    "print(move_group.get_current_pose())\n",
    "print(\"\")\n",
    "\n",
    "print(\"============ Printing robot current RPY\") #O/P wil be orientation of end-effector in RPY (Radians)\n",
    "#print(move_group.get_current_rpy())\n",
    "print(\"RPY In Degrees: \", np.degrees( move_group.get_current_rpy() ) )\n",
    "print(\"\")\n",
    "z_offset = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a31f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_coord_goal(move_group,coord):\n",
    "    pose_goal = geometry_msgs.msg.Pose()\n",
    "    pose_goal.position.x = coord[0]\n",
    "    pose_goal.position.y = coord[1]\n",
    "    pose_goal.position.z = coord[2]\n",
    "    pose_goal.orientation.x = coord[3]\n",
    "    pose_goal.orientation.y = coord[4]\n",
    "    pose_goal.orientation.z = coord[5]\n",
    "    pose_goal.orientation.w = coord[6]\n",
    "\n",
    "    move_group.set_pose_target(pose_goal)\n",
    "    \n",
    "    success = move_group.go(wait=True)\n",
    "    \n",
    "    move_group.stop()\n",
    "    move_group.clear_pose_targets()\n",
    "    current_pose = move_group.get_current_pose().pose\n",
    "\n",
    "\n",
    "\n",
    "def fetch_transform(tfbuffer,frame1,frame2,quat=0):\n",
    "    flag = 0\n",
    "    while flag==0:\n",
    "        try:\n",
    "            trans = tfbuffer.lookup_transform(frame1, frame2, rospy.Time(),rospy.Duration(8.0))\n",
    "            #print (trans)\n",
    "            trans = trans.transform  #save translation and rotation\n",
    "            #rot = PyKDL.Rotation.Quaternion(* [ trans.rotation.x,trans.rotation.y,trans.rotation.z,trans.rotation.w] )\n",
    "            #ypr = [ i  / np.pi * 180 for i in rot.GetEulerZYX() ]\n",
    "            #print(ypr[2],ypr[1],ypr[0])\n",
    "            \n",
    "            rot = R.from_quat([ trans.rotation.x,trans.rotation.y,trans.rotation.z,trans.rotation.w]) #creates rotation matrix\n",
    "            rpy = rot.as_euler('XYZ',degrees=True) #extrinsic\n",
    "            break\n",
    "        except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException) as e:\n",
    "            #print (\"Fail\", e)\n",
    "            continue\n",
    "    if quat==0:\n",
    "        return trans.translation.x, trans.translation.y, trans.translation.z, rpy[0],rpy[1],rpy[2] #ypr[2], ypr[1], ypr[0]\n",
    "    elif quat==1:\n",
    "        return trans.translation.x, trans.translation.y, trans.translation.z, trans.rotation.x, trans.rotation.y, trans.rotation.z, trans.rotation.w\n",
    "    \n",
    "\n",
    "def Publish_coordinates(Coordinates, parent_name, child_name, static = False): #Coordinates expects [[0,0,0,0,0,0,0],[1,1,1,1,1,1,1]] format\n",
    "\n",
    "    for index in range (len(Coordinates)):\n",
    "        \n",
    "        if static==True:\n",
    "            static_t.header.stamp = rospy.Time.now()\n",
    "            static_t.header.frame_id = parent_name\n",
    "            static_t.child_frame_id = child_name + \"_static_\"+str(index)\n",
    "            static_t.transform.translation.x = Coordinates[index][0]\n",
    "            static_t.transform.translation.y = Coordinates[index][1]\n",
    "            static_t.transform.translation.z = Coordinates[index][2]\n",
    "\n",
    "            #r_quat = tf.transformations.quaternion_from_euler(Roll,Pitch,Yaw)\n",
    "            static_t.transform.rotation.x = Coordinates[index][3]\n",
    "            static_t.transform.rotation.y = Coordinates[index][4]\n",
    "            static_t.transform.rotation.z = Coordinates[index][5]\n",
    "            static_t.transform.rotation.w = Coordinates[index][6]\n",
    "            static_br.sendTransform(static_t)\n",
    "        else:\n",
    "            t.header.frame_id = parent_name\n",
    "            t.child_frame_id = child_name + \"_\"+str(index)\n",
    "\n",
    "            t.header.stamp = rospy.Time.now()\n",
    "            t.transform.translation.x = Coordinates[index][0]\n",
    "            t.transform.translation.y = Coordinates[index][1]\n",
    "            t.transform.translation.z = Coordinates[index][2] \n",
    "\n",
    "            #r_quat = tf.transformations.quaternion_from_euler(Roll,Pitch,Yaw)\n",
    "            t.transform.rotation.x = Coordinates[index][3]\n",
    "            t.transform.rotation.y = Coordinates[index][4]\n",
    "            t.transform.rotation.z = Coordinates[index][5]\n",
    "            t.transform.rotation.w = Coordinates[index][6]\n",
    "            br.sendTransform(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f322bd",
   "metadata": {},
   "source": [
    "### This code will publish Camera target, where depth cam is supposed to go, visualize in Rviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a665e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_world_plane = fetch_transform(tfbuffer,'world', 'plane_static_0',quat=1)\n",
    "transform_link8_camera_depth_optical_frame = fetch_transform(tfbuffer,'panda_link8',\n",
    "                                                             'camera_depth_optical_frame',quat=1)\n",
    "\n",
    "#Translations\n",
    "trans_x =  transform_world_plane[0]\n",
    "trans_y = transform_world_plane[1]\n",
    "trans_z = transform_world_plane[2]\n",
    "\n",
    "KDL_original_frame = PyKDL.Frame(PyKDL.Rotation.Quaternion(transform_world_plane[3],transform_world_plane[4], \n",
    "                                           transform_world_plane[5], transform_world_plane[6]),\n",
    "                 PyKDL.Vector(trans_x, trans_y, trans_z))\n",
    "\n",
    "trans_x,trans_y,trans_z = KDL_original_frame * PyKDL.Vector(0, 0, z_offset) #Add offset\n",
    "\n",
    "#ROTATIONS\n",
    "#link8_to_cam_frame = R.from_quat([transform_link8_camera_depth_optical_frame[3], \n",
    "#                                  transform_link8_camera_depth_optical_frame[4], \n",
    "#                                  transform_link8_camera_depth_optical_frame[5], \n",
    "#                                  transform_link8_camera_depth_optical_frame[6]]) \n",
    "\n",
    "original_frame = R.from_quat([transform_world_plane[3], \n",
    "                              transform_world_plane[4], \n",
    "                              transform_world_plane[5], \n",
    "                              transform_world_plane[6]])\n",
    "\n",
    "flip_frame = R.from_euler('xyz', [180., 0., 180.], degrees=True) #To invert the frame\n",
    "\n",
    "final_frame = original_frame * flip_frame #link8_to_cam_frame * original_frame * flip_frame\n",
    "r_quat = final_frame.as_quat()\n",
    "\n",
    "final_coordinates = [trans_x, trans_y, trans_z, r_quat[0], r_quat[1], r_quat[2], r_quat[3]]\n",
    "Publish_coordinates([final_coordinates], \"world\", 'Camera_Target', static = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67850a7e",
   "metadata": {},
   "source": [
    "### This code does all the frame multiplication to make sure eef goes to its own target offset by camera target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19bd1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EEF\n",
    "#Translations\n",
    "trans_x = transform_world_plane[0]\n",
    "trans_y = transform_world_plane[1]\n",
    "trans_z = transform_world_plane[2]\n",
    "\n",
    "KDL_original_frame = PyKDL.Frame(PyKDL.Rotation.Quaternion(transform_world_plane[3],transform_world_plane[4], \n",
    "                                           transform_world_plane[5], transform_world_plane[6]),\n",
    "                 PyKDL.Vector(trans_x, trans_y, trans_z))\n",
    "\n",
    "trans_x,trans_y,trans_z = KDL_original_frame * PyKDL.Vector(transform_link8_camera_depth_optical_frame[0]\n",
    "                                            ,transform_link8_camera_depth_optical_frame[1]\n",
    "                                            ,transform_link8_camera_depth_optical_frame[2]+z_offset) # #Add offset\n",
    "\n",
    "#ROTATIONS\n",
    "link8_to_cam_frame = R.from_quat([transform_link8_camera_depth_optical_frame[3], \n",
    "                                  transform_link8_camera_depth_optical_frame[4], \n",
    "                                  transform_link8_camera_depth_optical_frame[5], \n",
    "                                  transform_link8_camera_depth_optical_frame[6]]) \n",
    "\n",
    "original_frame = R.from_quat([transform_world_plane[3], transform_world_plane[4], \n",
    "                              transform_world_plane[5], transform_world_plane[6]])\n",
    "\n",
    "flip_frame = R.from_euler('xyz', [180., 0., 180.], degrees=True) #To invert the frame\n",
    "\n",
    "final_frame = original_frame * link8_to_cam_frame * flip_frame \n",
    "r_quat = final_frame.as_quat()\n",
    "\n",
    "final_coordinates = [trans_x, trans_y, trans_z, r_quat[0], r_quat[1], r_quat[2], r_quat[3]]\n",
    "Publish_coordinates([final_coordinates], \"world\", 'EEF_Target', static = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40359172",
   "metadata": {},
   "source": [
    "### This code moves the robot EEF to desired coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7e3340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving to Target position\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#time.sleep(2)\n",
    "go_to_coord_goal(move_group, final_coordinates) #pass values to function to make robot move in cartesian space. \n",
    "print(\"Moving to Target position\")\n",
    "print(\"\")\n",
    "#time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88507d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18890475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839d9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8206f492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving to Target position\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform_world_plane = fetch_transform(tfbuffer,'world', 'plane_static_0',quat=1)\n",
    "transform_link8_camera_depth_optical_frame = fetch_transform(tfbuffer,'panda_link8',\n",
    "                                                             'camera_depth_optical_frame',quat=1)\n",
    "\n",
    "#Translations\n",
    "trans_x =  transform_world_plane[0]\n",
    "trans_y = transform_world_plane[1]\n",
    "trans_z = transform_world_plane[2]\n",
    "\n",
    "KDL_original_frame = PyKDL.Frame(PyKDL.Rotation.Quaternion(transform_world_plane[3],transform_world_plane[4], \n",
    "                                           transform_world_plane[5], transform_world_plane[6]),\n",
    "                 PyKDL.Vector(trans_x, trans_y, trans_z))\n",
    "\n",
    "trans_x,trans_y,trans_z = KDL_original_frame * PyKDL.Vector(0, 0, z_offset) #Add offset\n",
    "\n",
    "#ROTATIONS\n",
    "#link8_to_cam_frame = R.from_quat([transform_link8_camera_depth_optical_frame[3], \n",
    "#                                  transform_link8_camera_depth_optical_frame[4], \n",
    "#                                  transform_link8_camera_depth_optical_frame[5], \n",
    "#                                  transform_link8_camera_depth_optical_frame[6]]) \n",
    "\n",
    "original_frame = R.from_quat([transform_world_plane[3], \n",
    "                              transform_world_plane[4], \n",
    "                              transform_world_plane[5], \n",
    "                              transform_world_plane[6]])\n",
    "\n",
    "flip_frame = R.from_euler('xyz', [180., 0., 180.], degrees=True) #To invert the frame\n",
    "\n",
    "final_frame = original_frame * flip_frame #link8_to_cam_frame * original_frame * flip_frame\n",
    "r_quat = final_frame.as_quat()\n",
    "\n",
    "final_coordinates = [trans_x, trans_y, trans_z, r_quat[0], r_quat[1], r_quat[2], r_quat[3]]\n",
    "Publish_coordinates([final_coordinates], \"world\", 'Camera_Target', static = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#EEF\n",
    "#Translations\n",
    "trans_x = transform_world_plane[0]\n",
    "trans_y = transform_world_plane[1]\n",
    "trans_z = transform_world_plane[2]\n",
    "\n",
    "KDL_original_frame = PyKDL.Frame(PyKDL.Rotation.Quaternion(transform_world_plane[3],transform_world_plane[4], \n",
    "                                           transform_world_plane[5], transform_world_plane[6]),\n",
    "                 PyKDL.Vector(trans_x, trans_y, trans_z))\n",
    "\n",
    "trans_x,trans_y,trans_z = KDL_original_frame * PyKDL.Vector(transform_link8_camera_depth_optical_frame[0]\n",
    "                                            ,transform_link8_camera_depth_optical_frame[1]\n",
    "                                            ,transform_link8_camera_depth_optical_frame[2]+z_offset) # #Add offset\n",
    "\n",
    "#ROTATIONS\n",
    "link8_to_cam_frame = R.from_quat([transform_link8_camera_depth_optical_frame[3], \n",
    "                                  transform_link8_camera_depth_optical_frame[4], \n",
    "                                  transform_link8_camera_depth_optical_frame[5], \n",
    "                                  transform_link8_camera_depth_optical_frame[6]]) \n",
    "\n",
    "original_frame = R.from_quat([transform_world_plane[3], transform_world_plane[4], \n",
    "                              transform_world_plane[5], transform_world_plane[6]])\n",
    "\n",
    "flip_frame = R.from_euler('xyz', [180., 0., 180.], degrees=True) #To invert the frame\n",
    "\n",
    "final_frame = original_frame * link8_to_cam_frame * flip_frame \n",
    "r_quat = final_frame.as_quat()\n",
    "\n",
    "final_coordinates = [trans_x, trans_y, trans_z, r_quat[0], r_quat[1], r_quat[2], r_quat[3]]\n",
    "Publish_coordinates([final_coordinates], \"world\", 'EEF_Target', static = False)\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "go_to_coord_goal(move_group, final_coordinates) #pass values to function to make robot move in cartesian space. \n",
    "print(\"Moving to Target position\")\n",
    "print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
