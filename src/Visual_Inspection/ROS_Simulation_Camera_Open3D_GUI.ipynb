{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "from realsense2_camera.msg import Extrinsics\n",
    "\n",
    "from cv_bridge import CvBridge\n",
    "import rospy\n",
    "\n",
    "import pyrealsense2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import open3d as o3d\n",
    "from scipy import spatial\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import math\n",
    "import tf2_ros, tf\n",
    "import geometry_msgs.msg\n",
    "import PyKDL\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "from moveit_commander.conversions import pose_to_list\n",
    "\n",
    "import subprocess\n",
    "from ast import literal_eval\n",
    "import copy\n",
    "from PIL import Image as PIL_img\n",
    "from io import BytesIO\n",
    "from configparser import ConfigParser\n",
    "import glob\n",
    "\n",
    "image = None\n",
    "\n",
    "rospy.init_node(\"Cognitive_Motion\", anonymous=True)\n",
    "\n",
    "moveit_commander.roscpp_initialize(sys.argv)\n",
    "robot = moveit_commander.RobotCommander()\n",
    "scene = moveit_commander.PlanningSceneInterface()\n",
    "group_name = \"panda_manipulator\"  #\"panda_arm\"\n",
    "move_group = moveit_commander.MoveGroupCommander(group_name) #we'll pass it on while calling functions\n",
    "\n",
    "\n",
    "tfbuffer = tf2_ros.Buffer()\n",
    "listener = tf2_ros.TransformListener(tfbuffer)\n",
    "br = tf2_ros.TransformBroadcaster()\n",
    "t = geometry_msgs.msg.TransformStamped()\n",
    "\n",
    "static_br = tf2_ros.StaticTransformBroadcaster()\n",
    "static_t = geometry_msgs.msg.TransformStamped()\n",
    "\n",
    "bridge = CvBridge()\n",
    "loop_rate = rospy.Rate(0.5) # Node cycle rate (in Hz).\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "config = ConfigParser() #For config.ini\n",
    "\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_frame():\n",
    "    \n",
    "    frame_color=rospy.wait_for_message('/camera/color/image_raw', Image, timeout=None) #wait_for_message(topic, topic_type, timeout=None): \n",
    "    cv_image_color = bridge.imgmsg_to_cv2(frame_color, desired_encoding='rgb8')\n",
    "    \n",
    "    frame_depth = rospy.wait_for_message('/camera/depth/image_raw', Image, timeout=None) #wait_for_message(topic, topic_type, timeout=None): \n",
    "    cv_image_depth = bridge.imgmsg_to_cv2(frame_depth)\n",
    "    \n",
    "    return cv_image_color, cv_image_depth\n",
    "\n",
    "def get_cam_param(depth_to_color=False):\n",
    "    frame_depth_info=rospy.wait_for_message('/camera/depth/camera_info', CameraInfo, timeout=None)\n",
    "    \n",
    "    w = frame_depth_info.width\n",
    "    h = frame_depth_info.height\n",
    "    fx = frame_depth_info.K[0]\n",
    "    fy = frame_depth_info.K[4]\n",
    "    cx = frame_depth_info.K[2]\n",
    "    cy = frame_depth_info.K[5]\n",
    "    \n",
    "    if depth_to_color:\n",
    "        frame_depth_extrinsic=rospy.wait_for_message('/camera/extrinsics/depth_to_color', Extrinsics, timeout=None)\n",
    "        return w,h,fx,fy,cx,cy,frame_depth_extrinsic.translation,frame_depth_extrinsic.rotation\n",
    "    else:\n",
    "        rot = [1,0,0, 0,1,0, 0,0,1]\n",
    "        trans = [0, 0, 0]\n",
    "        return w,h,fx,fy,cx,cy, trans, rot\n",
    "\n",
    "def Generate_PointCloud(color_frame,depth_frame,trim_base,from_depth=False,depth_scale = 1000.0, depth_trunc=1.0,align=False,Dbug=False,zoom_def = 1.34): #Truncate distances at 1Meter default\n",
    "    \n",
    "    w,h,fx,fy,cx,cy, trans, rot = get_cam_param(depth_to_color=align)   \n",
    "\n",
    "    cam = o3d.camera.PinholeCameraParameters()\n",
    "    cam.intrinsic = o3d.camera.PinholeCameraIntrinsic(w, h, fx,fy, cx, cy)\n",
    "\n",
    "    cam.extrinsic = np.array([[rot[0], rot[1], rot[2], trans[0]], \n",
    "                              [rot[3], rot[4], rot[5], trans[1]], \n",
    "                              [rot[6], rot[7], rot[8], trans[2]], \n",
    "                              [0.    , 0.    , 0.    , 1.      ]])\n",
    "    \n",
    "\n",
    "    color_raw = o3d.geometry.Image(np.asarray(color_frame))\n",
    "    depth_raw = o3d.geometry.Image(np.asarray(depth_frame.astype(np.uint16)))\n",
    "    \n",
    "    if from_depth==False:\n",
    "        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, convert_rgb_to_intensity=False)\n",
    "        pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, cam.intrinsic, cam.extrinsic)\n",
    "        #CROP TO FILTER OUT ROBOT'S SHADOW ADJUST OFFSET ACCORDINGLY\n",
    "        PC_BBOX = pcd.get_axis_aligned_bounding_box()\n",
    "        minB_X = PC_BBOX.min_bound[0]\n",
    "        maxB_X = PC_BBOX.max_bound[0]\n",
    "        minB_Y = PC_BBOX.min_bound[1]\n",
    "        maxB_Y = PC_BBOX.max_bound[1]\n",
    "        minB_Z = PC_BBOX.min_bound[2]\n",
    "        maxB_Z = PC_BBOX.max_bound[2]\n",
    "        \n",
    "        #RAW Point cloud from depth\n",
    "        if Dbug==True:\n",
    "            mesh = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1,origin=[0, 0, 0])\n",
    "            o3d.visualization.draw_geometries([pcd,mesh], window_name='01_RAW Pointcloud: from Simulated Camera', point_show_normal=True, zoom=zoom_def, front=front_def, lookat=lookat_def, up=up_def)\n",
    "        \n",
    "        bbox = o3d.geometry.AxisAlignedBoundingBox(min_bound=(minB_X, minB_Y, minB_Z), \n",
    "                                                   max_bound=(maxB_X, maxB_Y, maxB_Z-trim_base)) #filter ground part \n",
    "        pcd = pcd.crop(bbox)\n",
    "        #pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, cam.intrinsic)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        pcd =  o3d.geometry.PointCloud.create_from_depth_image(depth_raw, cam.intrinsic, cam.extrinsic, \n",
    "                                                               depth_scale, depth_trunc,\n",
    "                                                               stride=1, project_valid_depth_only=True)\n",
    "        #RAW Point cloud from depth\n",
    "        if Dbug==True:\n",
    "            mesh = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1,origin=[0, 0, 0])\n",
    "            o3d.visualization.draw_geometries([pcd,mesh], window_name='01_RAW Pointcloud: from Real Camera', point_show_normal=True, zoom=zoom_def, front=front_def, lookat=lookat_def, up=up_def)\n",
    "\n",
    "    #pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down.\n",
    "\n",
    "\n",
    "    return pcd\n",
    "\n",
    "\n",
    "def tst_dataset(color_frame,depth_frame):\n",
    "    color_raw = o3d.geometry.Image(np.asarray(color_frame))\n",
    "    depth_raw = o3d.geometry.Image(np.asarray(depth_frame.astype(np.uint16)) )\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, convert_rgb_to_intensity=False)\n",
    "    pcd = visualize_rgbd(rgbd_image,align=False)\n",
    "    return pcd\n",
    "\n",
    "\n",
    "def box_pos(x_coord, y_coord, width, height, centered=0):\n",
    "    if centered == 0:\n",
    "        start_point = (x_coord, y_coord) # represents the top left corner of rectangle\n",
    "        end_point = (x_coord+width-1, y_coord+height-1)  # represents the bottom right corner of rectangle\n",
    "    elif centered == 1:\n",
    "        new_x = x_coord - (np.floor(width/2)-1).astype(int)\n",
    "        new_y = y_coord - (np.floor(height/2)-1).astype(int)\n",
    "        start_point = (new_x, new_y) \n",
    "        end_point = (new_x+width, new_y+height)\n",
    "    return start_point, end_point\n",
    "\n",
    "\n",
    "def fetch_transform(tfbuffer,frame1,frame2,quat=0):\n",
    "    flag = 0\n",
    "    while flag==0:\n",
    "        try:\n",
    "            trans = tfbuffer.lookup_transform(frame1, frame2, rospy.Time(),rospy.Duration(8.0))\n",
    "            #print (trans)\n",
    "            trans = trans.transform  #save translation and rotation\n",
    "            #rot = PyKDL.Rotation.Quaternion(* [ trans.rotation.x,trans.rotation.y,trans.rotation.z,trans.rotation.w] )\n",
    "            #ypr = [ i  / np.pi * 180 for i in rot.GetEulerZYX() ]\n",
    "            #print(ypr[2],ypr[1],ypr[0])\n",
    "            \n",
    "            rot = R.from_quat([ trans.rotation.x,trans.rotation.y,trans.rotation.z,trans.rotation.w]) #creates rotation matrix\n",
    "            rpy = rot.as_euler('XYZ',degrees=True) #extrinsic\n",
    "            break\n",
    "        except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException) as e:\n",
    "            #print (\"Fail\", e)\n",
    "            continue\n",
    "    if quat==0:\n",
    "        return trans.translation.x, trans.translation.y, trans.translation.z, rpy[0],rpy[1],rpy[2] #ypr[2], ypr[1], ypr[0]\n",
    "    elif quat==1:\n",
    "        return trans.translation.x, trans.translation.y, trans.translation.z, trans.rotation.x, trans.rotation.y, trans.rotation.z, trans.rotation.w\n",
    "    \n",
    "\n",
    "\n",
    "def Axis_angle_to_Quat(vector,angle):\n",
    "    x=vector[0]\n",
    "    y=vector[1]\n",
    "    z=vector[2]\n",
    "    qx = x * np.sin(angle/2)\n",
    "    qy = y * np.sin(angle/2)\n",
    "    qz = z * np.sin(angle/2)\n",
    "    qw = np.cos(angle/2)\n",
    "    \n",
    "    return qx,qy,qz,qw\n",
    "\n",
    "def Axis_angle_to_Euler(vector,angle):\n",
    "    x=vector[0]\n",
    "    y=vector[1]\n",
    "    z=vector[2]\n",
    "    s=np.sin(angle)\n",
    "    c=np.cos(angle)\n",
    "    t=1-c\n",
    "    \n",
    "    if ((x*y*t + z*s) > 0.998):  #north pole singularity detected\n",
    "        \n",
    "        heading = 2 * np.arctan2(x*np.sin(angle/2), np.cos(angle/2))\n",
    "        attitude = np.pi/2\n",
    "        bank = 0\n",
    "        return heading, attitude, bank\n",
    "    \n",
    "    elif ((x*y*t + z*s) < -0.998):\n",
    "        \n",
    "        heading = -2 * np.arctan2(x*np.sin(angle/2), np.cos(angle/2))\n",
    "        attitude = -np.pi/2\n",
    "        bank = 0\n",
    "        return heading, attitude, bank\n",
    "    \n",
    "    heading = np.arctan2(y * s- x * z * t , 1 - (y*y+ z*z ) * t)\n",
    "    attitude = np.arcsin(x * y * t + z * s)\n",
    "    bank = np.arctan2(x * s - y * z * t , 1 - (x*x + z*z) * t)\n",
    "    \n",
    "    return bank, heading, attitude\n",
    "\n",
    "\n",
    "def getRotation(v1):\n",
    "    if np.all(v1==[0., 0., 1.]): v1 = [0, 0.000001, 0.999999]\n",
    "    vec_x = [1.,0.,0.] \n",
    "    vec_y = [0.,1.,0.]\n",
    "    vec_z = [0.,0.,1.] #>>>>>>>>>>>>>>>>>>>>> change these to -1 to flip again\n",
    "    \n",
    "    vec1 = v1 / np.linalg.norm(v1)\n",
    "\n",
    "    #vector_x = np.cross(vec1, vec_x)/np.linalg.norm(np.cross(vec1, vec_x))\n",
    "    angle_x = (math.acos(np.dot(vec1, vec_x)))\n",
    "\n",
    "    #vector_y = np.cross(vec1, vec_y)/np.linalg.norm(np.cross(vec1, vec_y))\n",
    "    angle_y = (math.acos(np.dot(vec1, vec_y)))\n",
    "\n",
    "    vector_z = np.cross(vec1, vec_z)/np.linalg.norm(np.cross(vec1, vec_z))\n",
    "    angle_z = -(math.acos(np.dot(vec1, vec_z)))  #<<<Changed to adapt\n",
    "\n",
    "    #Rotation = filtered_Pt_Cloud.get_rotation_matrix_from_axis_angle(angle*vector) #alternative Open3D lib.\n",
    "    Rotation = R.from_rotvec(angle_z*vector_z)\n",
    "    \n",
    "    return Rotation, angle_x, angle_y, angle_z\n",
    "\n",
    "\n",
    "def Bounds_gen(minB, maxB, spacing):\n",
    "    ctr = 0\n",
    "    bounds = np.array([[0.,0.]])\n",
    "    CurrB = minB\n",
    "\n",
    "    while CurrB < maxB-0.5*spacing: #from left most to right most\n",
    "\n",
    "        LowerB = minB + ctr * spacing #if we shift the X or Y coordinates in multiples of spacing, we should get different lines.\n",
    "        if ctr == 0:\n",
    "            CurrB = LowerB + spacing/2 #lower + spacing/2 only for first condition\n",
    "        else:\n",
    "            CurrB = LowerB + spacing #lower + spacing\n",
    "        bounds = np.append(bounds,[[LowerB,CurrB]], axis=0)\n",
    "        #print(\"CurrB:\",CurrB,\"MaxB:\",maxB,\"diff:\",maxB-CurrB)\n",
    "        ctr+= 1\n",
    "    bounds = np.delete(bounds, 0, axis=0)\n",
    "    return bounds\n",
    "\n",
    "def cropped_PC(original_PC, spacing, Cluster_trim, X=0, idx = 0, centered = True, resample = True):\n",
    "    PC_BBOX = original_PC.get_axis_aligned_bounding_box()\n",
    "    minB_X = PC_BBOX.min_bound[0]\n",
    "    maxB_X = PC_BBOX.max_bound[0]\n",
    "    minB_Y = PC_BBOX.min_bound[1]\n",
    "    maxB_Y = PC_BBOX.max_bound[1]\n",
    "    minB_Z = PC_BBOX.min_bound[2]\n",
    "    maxB_Z = PC_BBOX.max_bound[2]\n",
    "    nor = np.array(original_PC.normals)\n",
    "    pts = np.array(original_PC.points)\n",
    "\n",
    "    Xs,Ys = get_XY_angles_from_PC(nor)\n",
    "    X_dev = np.std(Xs)\n",
    "    Y_dev = np.std(Ys)\n",
    "    print(\"X Standard Dev:\", X_dev, \"    Y Standard Dev:\", Y_dev)\n",
    "    \n",
    "    if(X > 1):\n",
    "        if(X==2): #Manual override at 2\n",
    "            X = 0  \n",
    "            print(\"Manual Override! taking curve around World Y-axis\",\"X=\", X)\n",
    "        elif(X==3):  #Manual override at 3\n",
    "            X = 1\n",
    "            print(\"Manual Override! taking curve around World X-axis\",\"X=\", X)\n",
    "        else: X = 1\n",
    "    else:\n",
    "        \n",
    "        if (X_dev <= Y_dev): \n",
    "            X = 1\n",
    "            print(\"Object's curve around World X-axis\",\"X=\", X)\n",
    "        elif (X_dev > Y_dev): \n",
    "            X = 0\n",
    "            print(\"Object's curve around World Y-axis\",\"X=\", X)\n",
    "\n",
    "    if X == 1: #X sided sweep crop\n",
    "        bounds = Bounds_gen(minB_X, maxB_X, spacing)\n",
    "        print(\"Total bounds:\",len(bounds))\n",
    "        if centered == True:\n",
    "            idx = int(np.floor(len(bounds)/2))\n",
    "        else:\n",
    "            if idx > len(bounds)-1:\n",
    "                print(\"Warning! Index value out of bounds, setting to max value\")\n",
    "                idx = -1\n",
    "        bbox = o3d.geometry.AxisAlignedBoundingBox(min_bound=(bounds[idx][0], minB_Y+Cluster_trim, minB_Z), \n",
    "                                                   max_bound=(bounds[idx][1], maxB_Y, maxB_Z)) #trim edges\n",
    "        result = original_PC.crop(bbox)\n",
    "        res_pts = np.array(result.points)\n",
    "        res_nor = np.array(result.normals)\n",
    "\n",
    "        if resample == True:\n",
    "            min_idx = np.argmin( np.std(res_pts, axis=0) )\n",
    "            res_pts[:, min_idx] = np.mean(res_pts,axis=0)[min_idx]  #replace values of axis (x,y or z)\n",
    "                                                                    #that has min std_dev by its mean.\n",
    "            result.points = o3d.utility.Vector3dVector(res_pts)\n",
    "            result = result.voxel_down_sample(voxel_size=spacing)\n",
    "        \n",
    "        res_pts = np.array(result.points)\n",
    "        res_nor = np.array(result.normals)\n",
    "\n",
    "        ind = np.argsort(res_pts[:, 1]) #Sort Y coordinates from lowest to highest, X values are almost constant\n",
    "        res_pts = res_pts[ind]  #no longer required to change values to negative \n",
    "        res_nor = res_nor[ind]\n",
    "\n",
    "    elif X == 0: #Y sided sweep crop\n",
    "        bounds = Bounds_gen(minB_Y, maxB_Y, spacing)\n",
    "        print(\"Total bounds:\",len(bounds))\n",
    "        if centered == True:\n",
    "            idx = int(np.floor(len(bounds)/2))\n",
    "        else:\n",
    "            if idx > len(bounds)-1:\n",
    "                print(\"Warning! Index value out of bounds, setting to max value\")\n",
    "                idx = -1\n",
    "        bbox = o3d.geometry.AxisAlignedBoundingBox(min_bound=(minB_X+Cluster_trim, bounds[idx][0], minB_Z), \n",
    "                                                   max_bound=(maxB_X, bounds[idx][1], maxB_Z))\n",
    "        print(bbox)\n",
    "\n",
    "        result = original_PC.crop(bbox)\n",
    "        res_pts = np.array(result.points)\n",
    "        res_nor = np.array(result.normals)\n",
    "        \n",
    "        if resample == True:\n",
    "            min_idx = np.argmin( np.std(res_pts, axis=0) )\n",
    "            res_pts[:, min_idx] = np.mean(res_pts,axis=0)[min_idx]  #replace values of axis (x,y or z)\n",
    "                                                                    #that has min std_dev by its mean.\n",
    "            result.points = o3d.utility.Vector3dVector(res_pts)\n",
    "            result = result.voxel_down_sample(voxel_size=spacing)\n",
    "        \n",
    "        res_pts = np.array(result.points)\n",
    "        res_nor = np.array(result.normals)\n",
    "\n",
    "        ind = np.argsort(res_pts[:, 0]) #Sort X coordinates from lowest to highest, Y values are almost constant\n",
    "        res_pts = res_pts[ind]\n",
    "        #res_pts[:,2] *=-1  #Change z values to negative\n",
    "        res_nor = res_nor[ind]\n",
    "\n",
    "    sorted_pointcloud = o3d.geometry.PointCloud()\n",
    "    sorted_pointcloud.points = o3d.utility.Vector3dVector(res_pts)\n",
    "    sorted_pointcloud.normals = o3d.utility.Vector3dVector(res_nor)\n",
    "\n",
    "    return sorted_pointcloud\n",
    "\n",
    "\n",
    "def generate_coordinates(point_cloud,silent=True):\n",
    "    Coordinates = np.array([[0.,0.,0.,0.,0.,0.,0.]])\n",
    "    world_Coordinates = np.array([[0.,0.,0.,0.,0.,0.,0.]])\n",
    "    point_cloud_pts = np.array(point_cloud.points)\n",
    "    point_cloud_nor = np.array(point_cloud.normals)\n",
    "    \n",
    "    for index in range (len(point_cloud_pts)):\n",
    "\n",
    "        rotat, angle_x, angle_y, angle_z = getRotation(-point_cloud_nor[index])  #<<<changed here pts -ve\n",
    "\n",
    "        a1 = rotat.as_matrix()[0][0]\n",
    "        a2 = rotat.as_matrix()[0][1]\n",
    "        a3 = rotat.as_matrix()[0][2]\n",
    "        b1 = rotat.as_matrix()[1][0]\n",
    "        b2 = rotat.as_matrix()[1][1]\n",
    "        b3 = rotat.as_matrix()[1][2]\n",
    "        c1 = rotat.as_matrix()[2][0]\n",
    "        c2 = rotat.as_matrix()[2][1]\n",
    "        c3 = rotat.as_matrix()[2][2]\n",
    "\n",
    "        KDL_original_plane_frame = PyKDL.Frame(PyKDL.Rotation(a1,a2,a3, b1,b2,b3, c1,c2,c3),\n",
    "                                               PyKDL.Vector(point_cloud_pts[index][0],\n",
    "                                                            point_cloud_pts[index][1],\n",
    "                                                             point_cloud_pts[index][2]))\n",
    "\n",
    "        KDL_flip_frame = PyKDL.Frame(PyKDL.Rotation.RPY(0, np.pi, 0), PyKDL.Vector(0,0,0)) #mirror plane frame to match camera frame\n",
    "        KDL_final_frame = KDL_original_plane_frame * KDL_flip_frame\n",
    "        KDL_trans = KDL_final_frame.p\n",
    "        KDL_ROT_quat = KDL_final_frame.M.GetQuaternion() \n",
    "\n",
    "        Coordinates = np.append(Coordinates,[[KDL_trans[0] ,KDL_trans[1],KDL_trans[2] ,KDL_ROT_quat[0] \n",
    "                                     ,KDL_ROT_quat[1] ,KDL_ROT_quat[2],KDL_ROT_quat[3]]],axis=0)\n",
    "\n",
    "        Publish_coordinates([[KDL_trans[0] ,KDL_trans[1],KDL_trans[2] ,KDL_ROT_quat[0] \n",
    "                            ,KDL_ROT_quat[1] ,KDL_ROT_quat[2],KDL_ROT_quat[3]]], \n",
    "                            'camera_depth_optical_frame', 'plane', static = True)\n",
    "\n",
    "        transform_plane = fetch_transform(tfbuffer,'world', 'plane_static_0',quat=1)\n",
    "\n",
    "        world_Coordinates = np.append(world_Coordinates,[[transform_plane[0] ,transform_plane[1]\n",
    "                                            ,transform_plane[2] ,transform_plane[3] ,transform_plane[4] \n",
    "                                             ,transform_plane[5] ,transform_plane[6]]],axis=0)\n",
    "        #time.sleep(0.03)\n",
    "    Coordinates = np.delete(Coordinates, 0, axis=0)\n",
    "    world_Coordinates2 = np.delete(world_Coordinates, 0, axis=0)\n",
    "    \n",
    "    ctr = 0\n",
    "    vote=0\n",
    "    diff_neg_x = np.sum(np.diff(world_Coordinates2[:,0:1],axis=0 ) < 0)\n",
    "    diff_pos_x = np.sum(np.diff(world_Coordinates2[:,0:1],axis=0 ) >= 0)\n",
    "    diff_neg_y = np.sum(np.diff(world_Coordinates2[:,1:2],axis=0 ) < 0)\n",
    "    diff_pos_y = np.sum(np.diff(world_Coordinates2[:,1:2],axis=0 ) >= 0)\n",
    "    diff_neg_z = np.sum(np.diff(world_Coordinates2[:,2:3],axis=0 ) < 0)\n",
    "    diff_pos_z = np.sum(np.diff(world_Coordinates2[:,2:3],axis=0 ) >= 0)\n",
    "    #print(diff_neg_x, diff_pos_x, diff_neg_y, diff_pos_y, diff_neg_z, diff_pos_z)\n",
    "    while True: #check for anomalies in data\n",
    "        idx = int(len(world_Coordinates2)/2)\n",
    "        #Series is decresing and current number is bigger than middle one, no need to move or reverse.\n",
    "        if (diff_neg_x>diff_pos_x and world_Coordinates2[0,0:1] >= world_Coordinates2[idx,0:1]) or (\n",
    "            diff_neg_x<diff_pos_x and world_Coordinates2[0,0:1] < world_Coordinates2[idx,0:1]):\n",
    "            #print(\"no need to move\")\n",
    "            vote += 0\n",
    "        elif (diff_neg_x>diff_pos_x and world_Coordinates2[0,0:1] < world_Coordinates2[idx,0:1]) or (\n",
    "            diff_neg_x<diff_pos_x and world_Coordinates2[0,0:1] >= world_Coordinates2[idx,0:1]):\n",
    "            #print(\"move to last\")\n",
    "            vote += 1\n",
    "\n",
    "        if (diff_neg_y > diff_pos_y and world_Coordinates2[0,1:2] >= world_Coordinates2[idx,1:2]) or (\n",
    "            diff_neg_y < diff_pos_y and world_Coordinates2[0,1:2] < world_Coordinates2[idx,1:2]):\n",
    "            #print(\"no need to move\")\n",
    "            vote += 0\n",
    "        elif (diff_neg_y > diff_pos_y and world_Coordinates2[0,1:2] < world_Coordinates2[idx,1:2]) or (\n",
    "            diff_neg_y < diff_pos_y and world_Coordinates2[0,1:2] >= world_Coordinates2[idx,1:2]):\n",
    "            #print(\"move to last\")\n",
    "            vote += 1\n",
    "\n",
    "        if (diff_neg_z > diff_pos_z and world_Coordinates2[0,2:3] >= world_Coordinates2[idx,2:3]) or (\n",
    "            diff_neg_z < diff_pos_z and world_Coordinates2[0,2:3] < world_Coordinates2[idx,2:3]):\n",
    "            #print(\"no need to move\")\n",
    "            vote += 0\n",
    "        elif (diff_neg_z > diff_pos_z and world_Coordinates2[0,2:3] < world_Coordinates2[idx,2:3]) or (\n",
    "            diff_neg_z < diff_pos_z and world_Coordinates2[0,2:3] >= world_Coordinates2[idx,2:3]):\n",
    "            #print(\"move to last\")\n",
    "            vote += 1\n",
    "        #print(\"vote:\",vote)\n",
    "\n",
    "        if vote >= 2:\n",
    "            #Coordinates = np.roll(Coordinates, -1, axis=0)\n",
    "            #world_Coordinates2 = np.roll(world_Coordinates2, -1, axis=0)\n",
    "            Coordinates = np.delete(Coordinates, 0, axis=0)\n",
    "            world_Coordinates2 = np.delete(world_Coordinates2, 0, axis=0)\n",
    "\n",
    "            ctr+=1\n",
    "            vote=0\n",
    "        else:\n",
    "            if not silent:\n",
    "                print(\"number of rolls:\",ctr)\n",
    "            break\n",
    "\n",
    "\n",
    "#    while True:\n",
    "#        if np.count_nonzero( (world_Coordinates2[0][:3] >= world_Coordinates2[idx][:3]) ) < 2:\n",
    "#            Coordinates = np.roll(Coordinates, -1, axis=0)\n",
    "#            world_Coordinates2 = np.roll(world_Coordinates2, -1, axis=0)\n",
    "#            ctr+=1\n",
    "#        else:\n",
    "#            if not silent:\n",
    "#                print(\"number of rolls:\",ctr)\n",
    "#            break\n",
    "\n",
    "\n",
    "            \n",
    "    world_Coordinates2, idx_wc = np.unique(world_Coordinates2, axis=0, return_index=True)\n",
    "    world_Coordinates2 = world_Coordinates2[np.argsort(idx_wc)]\n",
    "    \n",
    "    Coordinates, idx_wc = np.unique(Coordinates, axis=0, return_index=True)\n",
    "    Coordinates = Coordinates[np.argsort(idx_wc)]\n",
    "    \n",
    "    return Coordinates, world_Coordinates2\n",
    "\n",
    "def Publish_coordinates(Coordinates, parent_name, child_name, static = False): #Coordinates expects [[0,0,0,0,0,0,0],[1,1,1,1,1,1,1]] format\n",
    "\n",
    "    for index in range (len(Coordinates)):\n",
    "        \n",
    "        if static==True:\n",
    "            static_t.header.stamp = rospy.Time.now()\n",
    "            static_t.header.frame_id = parent_name #\"camera_depth_optical_frame\"\n",
    "            static_t.child_frame_id = child_name+\"_static_\"+str(index)\n",
    "            static_t.transform.translation.x = Coordinates[index][0]\n",
    "            static_t.transform.translation.y = Coordinates[index][1]\n",
    "            static_t.transform.translation.z = Coordinates[index][2]\n",
    "\n",
    "            #r_quat = tf.transformations.quaternion_from_euler(Roll,Pitch,Yaw)\n",
    "            static_t.transform.rotation.x = Coordinates[index][3]\n",
    "            static_t.transform.rotation.y = Coordinates[index][4]\n",
    "            static_t.transform.rotation.z = Coordinates[index][5]\n",
    "            static_t.transform.rotation.w = Coordinates[index][6]\n",
    "            static_br.sendTransform(static_t)\n",
    "        else:\n",
    "            t.header.frame_id = parent_name #\"camera_depth_optical_frame\"\n",
    "            t.child_frame_id = child_name+\"_\"+str(index)\n",
    "\n",
    "            t.header.stamp = rospy.Time.now()\n",
    "            t.transform.translation.x = Coordinates[index][0]\n",
    "            t.transform.translation.y = Coordinates[index][1]\n",
    "            t.transform.translation.z = Coordinates[index][2] \n",
    "\n",
    "            #r_quat = tf.transformations.quaternion_from_euler(Roll,Pitch,Yaw)\n",
    "            t.transform.rotation.x = Coordinates[index][3]\n",
    "            t.transform.rotation.y = Coordinates[index][4]\n",
    "            t.transform.rotation.z = Coordinates[index][5]\n",
    "            t.transform.rotation.w = Coordinates[index][6]\n",
    "            br.sendTransform(t)\n",
    "\n",
    "\n",
    "\n",
    "def Cluster_Point_Cloud(original_PC, eps=0.02, min_points=10):\n",
    "\n",
    "    labels = np.array(original_PC.cluster_dbscan(eps=eps, min_points=min_points))\n",
    "    uniques = np.unique(labels)\n",
    "    clouds = np.array(original_PC)\n",
    "    \n",
    "    if ((uniques[0] == -1) and (len(uniques) == 1)):\n",
    "        clouds = np.append(clouds,[original_PC])\n",
    "\n",
    "    else:\n",
    "        for i in range (len(uniques)):\n",
    "\n",
    "            if uniques[i] > -1:\n",
    "                idx = np.where(labels==uniques[i])[0]\n",
    "                cluster_pcd = original_PC.select_by_index(idx, invert=False)\n",
    "                clouds = np.append(clouds,[cluster_pcd])\n",
    "\n",
    "    clouds = np.delete(clouds, 0)\n",
    "    print(\"Number of clusters:\", len(clouds))\n",
    "    return clouds\n",
    "\n",
    "\n",
    "def go_to_coord_goal(move_group,coord):\n",
    "    pose_goal = geometry_msgs.msg.Pose()\n",
    "    pose_goal.position.x = coord[0]\n",
    "    pose_goal.position.y = coord[1]\n",
    "    pose_goal.position.z = coord[2]\n",
    "    pose_goal.orientation.x = coord[3]\n",
    "    pose_goal.orientation.y = coord[4]\n",
    "    pose_goal.orientation.z = coord[5]\n",
    "    pose_goal.orientation.w = coord[6]\n",
    "\n",
    "    move_group.set_pose_target(pose_goal)\n",
    "    \n",
    "    success = move_group.go(wait=True)\n",
    "    \n",
    "    move_group.stop()\n",
    "    move_group.clear_pose_targets()\n",
    "    #current_pose = move_group.get_current_pose().pose\n",
    "\n",
    "def go_to_joint_state(move_group,joint_goal):\n",
    "    success = move_group.go(joint_goal, wait=True)\n",
    "    move_group.stop()\n",
    "\n",
    "def array_to_data(array):\n",
    "    im = PIL_img.fromarray(array)\n",
    "    output_buffer = BytesIO()\n",
    "    im.save(output_buffer, format=\"PNG\")\n",
    "    data = output_buffer.getvalue()\n",
    "    return data\n",
    "\n",
    "def fetch_cloud_image(pointCloud, RX=0, RY=0, RZ=0):\n",
    "    mesh = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1,origin=[0, 0, 0])\n",
    "    mesh_pc= mesh.sample_points_uniformly(number_of_points=1000000, use_triangle_normal=False)\n",
    "    tmp_cloud = copy.deepcopy(pointCloud)  #To avoid overwriting the original point cloud\n",
    "    \n",
    "    tmp_cloud+=mesh_pc\n",
    "    tmp_Rot = pointCloud.get_rotation_matrix_from_xyz((np.radians(RX), np.radians(RY), np.radians((RZ))))\n",
    "    \n",
    "    tmp_cloud.rotate(tmp_Rot, center=(0, 0, 0))\n",
    "    \n",
    "    vis = o3d.visualization.Visualizer() \n",
    "    vis.create_window(visible=False, width=640, height=480) \n",
    "    vis.add_geometry(tmp_cloud) \n",
    "    vis.poll_events() \n",
    "    vis.update_renderer() \n",
    "    color = vis.capture_screen_float_buffer(True) \n",
    "    #time.sleep(5)\n",
    "    vis.destroy_window() \n",
    "    #color = np.asarray(color)\n",
    "    color = (255.0 * np.asarray(color)).astype(np.uint8)\n",
    "    color = array_to_data(color) #Format according to the GUI requirements\n",
    "    return color\n",
    "\n",
    "def Cluster_selection_gui(clouds):\n",
    "    dat=[]  #to hold cluster's images\n",
    "    pcd_combined = o3d.geometry.PointCloud()\n",
    "    \n",
    "    for current_cloud in clouds:\n",
    "            color = fetch_cloud_image(current_cloud, RX=120,RZ=180)  #different point clouds to be viewed, set view by RX,RY,RZ\n",
    "            dat.append(color)\n",
    "    result = subprocess.run([sys.executable,  \"Cluster_selection_gui.py\"],capture_output=True,text=True,check=True,shell=False, input=repr(dat))   \n",
    "    OP = literal_eval(result.stdout)\n",
    "    selected_PC = OP[0]\n",
    "    selected_motion = OP[1]\n",
    "    \n",
    "    for k in selected_PC:\n",
    "        pcd_combined += clouds[k]  #combine selected pointclouds \n",
    "    return pcd_combined, selected_motion\n",
    "\n",
    "#def Convert_message(string):\n",
    "#    return [int(s) for s in re.findall('[0-9]', string)]\n",
    "\n",
    "def get_XY_angles_from_PC(tst_downpcd_nor):\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    vec_x = [1.,0.,0.] \n",
    "    vec_y = [0.,1.,0.]\n",
    "    \n",
    "    for normal_vec in tst_downpcd_nor:\n",
    "        if np.all(normal_vec==[0., 0., 1.]): normal_vec = [0, 0.000001, 0.999999]\n",
    "        vec1 = normal_vec / np.linalg.norm(normal_vec)\n",
    "        angle_x = np.round(np.degrees((math.acos(np.dot(vec1, vec_x)))))\n",
    "        angle_y = np.round(np.degrees((math.acos(np.dot(vec1, vec_y)))))\n",
    "        Xs.append(angle_x)\n",
    "        Ys.append(angle_y)\n",
    "    Xs = np.array(Xs)\n",
    "    Ys = np.array(Ys)\n",
    "    return Xs, Ys\n",
    "\n",
    "\n",
    "def Generate_final_coordinates(world_coords, z_offset, eef_link, coord_skip=3):\n",
    "\n",
    "    Cam_target_final_coordinates=[]\n",
    "    EEF_target_final_coordinates=[]\n",
    "\n",
    "    for id_x in range(0,len(world_coords),coord_skip):  #Take every 4th point in coordinates\n",
    "        transform_world_plane = world_coords[id_x]\n",
    "        KDL_original_plane_frame = PyKDL.Frame(PyKDL.Rotation.Quaternion(transform_world_plane[3],\n",
    "                                                                         transform_world_plane[4], \n",
    "                                                                         transform_world_plane[5], \n",
    "                                                                         transform_world_plane[6]),\n",
    "                                               PyKDL.Vector(transform_world_plane[0], \n",
    "                                                            transform_world_plane[1], \n",
    "                                                            transform_world_plane[2]))\n",
    "\n",
    "        trans_x,trans_y,trans_z = KDL_original_plane_frame * PyKDL.Vector(0, 0, z_offset) #Add offset\n",
    "        KDL_original_plane_frame.p = PyKDL.Vector(trans_x,trans_y,trans_z) #update original plane frame to new location\n",
    "\n",
    "        KDL_flip_frame = PyKDL.Frame(PyKDL.Rotation.RPY(np.pi, 0.,np.pi), PyKDL.Vector(0, 0, 0)) #mirror plane frame to match camera frame\n",
    "\n",
    "        KDL_final_frame = KDL_original_plane_frame * KDL_flip_frame\n",
    "\n",
    "        KDL_trans = KDL_final_frame.p\n",
    "        KDL_ROT_quat = KDL_final_frame.M.GetQuaternion() \n",
    "\n",
    "        final_coordinates = [KDL_trans[0], KDL_trans[1], KDL_trans[2], KDL_ROT_quat[0], KDL_ROT_quat[1], \n",
    "                                                                       KDL_ROT_quat[2], KDL_ROT_quat[3]]\n",
    "        #print(final_coordinates)\n",
    "        #Publish_coordinates([final_coordinates], \"world\", 'Camera_Target', static = False)\n",
    "\n",
    "        Cam_target_final_coordinates.append(final_coordinates)\n",
    "\n",
    "        #Fetch transform between eef link (link8, or tcp) and optical depth cam\n",
    "        transform_eef_camera_depth = fetch_transform(tfbuffer,'camera_depth_optical_frame', eef_link, quat=1)\n",
    "\n",
    "        KDL_eef_cam_frame = PyKDL.Frame(PyKDL.Rotation.Quaternion(transform_eef_camera_depth[3],\n",
    "                                                                    transform_eef_camera_depth[4], \n",
    "                                                                    transform_eef_camera_depth[5],\n",
    "                                                                    transform_eef_camera_depth[6]),\n",
    "                                          PyKDL.Vector(transform_eef_camera_depth[0], \n",
    "                                                       transform_eef_camera_depth[1], \n",
    "                                                       transform_eef_camera_depth[2])) #eef-camera frame\n",
    "\n",
    "        #Offset original frame by z offset, flip the frame to match camera, multiply with eef-camera frame to \n",
    "        #replicate pose between camera and eef\n",
    "        KDL_final_frame = KDL_original_plane_frame * KDL_flip_frame * KDL_eef_cam_frame \n",
    "\n",
    "        KDL_trans = KDL_final_frame.p\n",
    "        KDL_ROT_quat = KDL_final_frame.M.GetQuaternion() \n",
    "\n",
    "        final_coordinates = [KDL_trans[0], KDL_trans[1], KDL_trans[2], KDL_ROT_quat[0], KDL_ROT_quat[1], \n",
    "                                                                       KDL_ROT_quat[2], KDL_ROT_quat[3]]\n",
    "        #Publish_coordinates([final_coordinates], \"world\", 'EEF_Target', static = True)\n",
    "        EEF_target_final_coordinates.append(final_coordinates)\n",
    "        \n",
    "    #Cam_target_final_coordinates.append(Cam_target_final_coordinates.pop(0))  #first element to last\n",
    "    #EEF_target_final_coordinates.append(EEF_target_final_coordinates.pop(0))  #first element to last\n",
    "    #Cam_target_final_coordinates.pop(0)\n",
    "    #EEF_target_final_coordinates.pop(0)\n",
    "    return Cam_target_final_coordinates, EEF_target_final_coordinates\n",
    "\n",
    "def filter_generate_coordinates(result, spacing, sample = 3, silent=True, remove_close_targets=True): \n",
    "    #This will sample generated coordinates and compare to find the ones with anomalies and discard them\n",
    "    CC = []\n",
    "    WC = []\n",
    "    dist =[]\n",
    "    if sample < 3:\n",
    "        print(\"Warning! min samples required: 3, seting to 3.\")\n",
    "        sample=3\n",
    "    for i in range(0,sample):\n",
    "        cam_coords, world_coords = generate_coordinates(result,silent=False)\n",
    "\n",
    "        median = np.median(world_coords[:,:3],axis=0)\n",
    "        distance = np.mean(np.linalg.norm(median - world_coords[:,:3], axis=1))\n",
    "        CC.append(cam_coords)\n",
    "        WC.append(world_coords)\n",
    "        dist.append(distance)\n",
    "    selection = np.argwhere(abs(np.ediff1d(dist)) < np.median(abs(np.ediff1d(dist))))[0][0]\n",
    "    cam_T = CC[selection]\n",
    "    WC_T = WC[selection]\n",
    "    \n",
    "    if remove_close_targets==True:\n",
    "        i = 0\n",
    "        while True:\n",
    "            #print(i, len(WC_T))\n",
    "            dis = spatial.distance.euclidean(WC_T[i-1][:3], WC_T[i][:3])\n",
    "            #print(i-1,i, dis)\n",
    "            if dis < 2*spacing:\n",
    "                WC_T = np.delete(WC_T, i,axis=0)\n",
    "                cam_T = np.delete(cam_T, i,axis=0)\n",
    "            else:\n",
    "                i+=1\n",
    "            if i >= len(WC_T):\n",
    "                break       \n",
    "    \n",
    "    return cam_T, WC_T\n",
    "\n",
    "def Front_gui(data_in=0):\n",
    "    result = subprocess.run([sys.executable,  \"Front_gui.py\"],capture_output=True,text=True,check=True,shell=False, input=repr(data_in))\n",
    "    data_out = literal_eval(result.stdout)\n",
    "    return data_out\n",
    "\n",
    "def Setting_gui(data_in):\n",
    "\n",
    "    result = subprocess.run([sys.executable,  \"Settings_gui.py\"],capture_output=True,text=True,check=True,shell=False, input=repr(data_in))\n",
    "    data_out = literal_eval(result.stdout)\n",
    "    return data_out\n",
    "\n",
    "def Manual_gui(manual_offset, TGT_save):\n",
    "    \n",
    "    dat=[]  #to hold images\n",
    "    for f in sorted(glob.iglob(\"VI_appdata/Robo_object_positions/*\")):\n",
    "        im = PIL_img.open(f)\n",
    "        output_buffer = BytesIO()\n",
    "        im.save(output_buffer, format=\"PNG\")\n",
    "        data = output_buffer.getvalue()\n",
    "        dat.append(data)\n",
    "   \n",
    "    result = subprocess.run([sys.executable,  \"Manual_gui.py\"],capture_output=True,text=True,check=True,shell=False, input=repr([dat,manual_offset, TGT_save]))   \n",
    "\n",
    "    OP = literal_eval(result.stdout)\n",
    "    return OP[0], OP[1], OP[2],OP[3] #pose_idx, man_offset, TGT_save, Exit_flag\n",
    "\n",
    "def Auto_gui(manual_offset, TGT_save):\n",
    "    \n",
    "    dat=[]  #to hold images\n",
    "    for f in sorted(glob.iglob(\"VI_appdata/Robo_object_positions/*\")):\n",
    "        im = PIL_img.open(f)\n",
    "        output_buffer = BytesIO()\n",
    "        im.save(output_buffer, format=\"PNG\")\n",
    "        data = output_buffer.getvalue()\n",
    "        dat.append(data)\n",
    "   \n",
    "    result = subprocess.run([sys.executable,  \"Auto_gui.py\"],capture_output=True,text=True,check=True,shell=False, input=repr([dat,manual_offset, TGT_save]))   \n",
    "\n",
    "    OP = literal_eval(result.stdout)\n",
    "     #selected_mode, man_offset, cluster_idx, selected_motion, TGT_save, iterations,Hide_prev,Exit_flag\n",
    "    return OP[0], OP[1], OP[2], OP[3], OP[4], OP[5], OP[6], OP[7]\n",
    "\n",
    "\n",
    "def Replay_gui(file_path, X_offset, Y_offset, Z_offset, TGT_save):\n",
    "      \n",
    "    result = subprocess.run([sys.executable,  \"Replay_gui.py\"],capture_output=True,text=True,check=True,shell=False, input=repr([file_path, X_offset, Y_offset, Z_offset, TGT_save]))   \n",
    "\n",
    "    OP = literal_eval(result.stdout)\n",
    "    return OP[0], OP[1], OP[2], OP[3], OP[4], OP[5] #file_path, X_offset, Y_offset, Z_offset, TGT_save, OK_flag\n",
    "\n",
    "\n",
    "def Save_gui():\n",
    "      \n",
    "    result = subprocess.run([sys.executable,  \"Save_gui.py\"],capture_output=True,text=True,check=True,shell=False, input=repr([0]))   \n",
    "    OP = literal_eval(result.stdout)\n",
    "    return OP[0], OP[1] #file_path, Save_mode\n",
    "\n",
    "\n",
    "def get_average_pt_cloud(offset_y,offset_z,trim_base,Dbug):\n",
    "    zoom_def = 1.34\n",
    "    cam_robo_depth = abs(fetch_transform(tfbuffer,'camera_depth_optical_frame', 'panda_link0',quat=0)[2]) #get z value\n",
    "    color_frame, depth_frame = grab_frame()\n",
    "    downpcd = Generate_PointCloud(color_frame,depth_frame,trim_base,from_depth=False, \n",
    "                                  depth_trunc = cam_robo_depth - trim_base, align=False,Dbug=Dbug) #Take from 4cm above ground\n",
    "    \n",
    "    #CROP TO FILTER OUT ROBOT'S SHADOW ADJUST OFFSET ACCORDINGLY\n",
    "    PC_BBOX = downpcd.get_axis_aligned_bounding_box()\n",
    "    minB_X = PC_BBOX.min_bound[0]\n",
    "    maxB_X = PC_BBOX.max_bound[0]\n",
    "    minB_Y = PC_BBOX.min_bound[1]\n",
    "    maxB_Y = PC_BBOX.max_bound[1]\n",
    "    minB_Z = PC_BBOX.min_bound[2]\n",
    "    maxB_Z = PC_BBOX.max_bound[2]\n",
    "\n",
    "    bbox = o3d.geometry.AxisAlignedBoundingBox(min_bound=(minB_X, minB_Y, minB_Z), \n",
    "                                               max_bound=(maxB_X, maxB_Y-offset_y, maxB_Z-offset_z)) \n",
    "    downpcd = downpcd.crop(bbox)\n",
    "\n",
    "    if Dbug==True:\n",
    "        mesh = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1,origin=[0, 0, 0])\n",
    "        o3d.visualization.draw_geometries([downpcd,mesh], window_name=\"02_Filtered Pointcloud: Remove Ground and Robot\", point_show_normal=True, zoom=zoom_def, front=front_def, lookat=lookat_def, up=up_def)\n",
    "\n",
    "    return downpcd\n",
    "\n",
    "\n",
    "def Load_PC(samples,offset_y,offset_z,spacing,trim_base,Hide_prev=False,Dbug=False):\n",
    "    zoom_def = 1.34\n",
    "    front_def = [ -0.38077889171563734, 0.78942164088651434, -0.48147783804018851 ]\n",
    "    lookat_def = [ 0.16328584993371112, 0.10901604638723184, 0.39735867391549773 ]\n",
    "    up_def = [ 0.17393478184042019, -0.45025906577602964, -0.87579304938588232 ]\n",
    "\n",
    "    if (Hide_prev==False or Dbug==True):\n",
    "        mesh = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1,origin=[0, 0, 0])\n",
    "    \n",
    "    \n",
    "    average_ptcloud = o3d.geometry.PointCloud()\n",
    "\n",
    "    pts_cloud_tot = []\n",
    "    pts_tot = []\n",
    "\n",
    "    for i in range(samples):\n",
    "        new_pt = get_average_pt_cloud(offset_y,offset_z,trim_base,Dbug)\n",
    "        #average_ptcloud += new_pt\n",
    "        pts_cloud_tot.append(new_pt)\n",
    "        pts_tot.append(len(np.asarray(new_pt.points)))\n",
    "\n",
    "\n",
    "    #Collected Point clouds\n",
    "    if Dbug==True:\n",
    "        snip = pts_cloud_tot\n",
    "        snip.append(mesh)\n",
    "        o3d.visualization.draw_geometries(snip, window_name=\"03_Sampled Pointclouds\", point_show_normal=True, zoom=zoom_def, front=front_def, lookat=lookat_def, up=up_def)\n",
    "\n",
    "\n",
    "    ## We'll select only those point clouds that have a majority of similar \"number of points\". \n",
    "    ## this will prevent any outlier point clouds that have weird data in it (like less points \n",
    "    ## or more points than the group)\n",
    "\n",
    "    bins = np.linspace(np.min(pts_tot), np.max(pts_tot), int(np.ceil(samples/3)))  #generate bins in range of number of pts in ptcloud\n",
    "    digitized = np.digitize(pts_tot, bins) #put values in bins based on size of point clouds\n",
    "\n",
    "    uni, count = np.unique(digitized,return_counts=True) #get the uniques and their counts\n",
    "    unique_val = uni[np.argmax(count)]  #get the value from unique list where count was maximum\n",
    "    idx_list = np.where(digitized == unique_val)[0]  #get all indexes from digitized list where it matches unique\n",
    "\n",
    "    for idx in idx_list:\n",
    "        average_ptcloud += pts_cloud_tot[idx]\n",
    "\n",
    "    #Average pointcloud having majority of similar point clouds\n",
    "    if Dbug==True:\n",
    "        o3d.visualization.draw_geometries([average_ptcloud,mesh], window_name=\"04_Filtered Pointcloud: Select valid pointclouds by majority vote\", point_show_normal=True, zoom=zoom_def, front=front_def, lookat=lookat_def, up=up_def)\n",
    "\n",
    "\n",
    "    ## Filter out hidden points\n",
    "    diameter = np.linalg.norm(np.asarray(average_ptcloud.get_max_bound()) - np.asarray(average_ptcloud.get_min_bound()))\n",
    "    cam = [0, 0, -diameter]  #[0, 0, diameter]\n",
    "    radius = diameter * 100\n",
    "    _, pt_map = average_ptcloud.hidden_point_removal(cam, radius) #Get all points that are visible from given view point\n",
    "    average_ptcloud = average_ptcloud.select_by_index(pt_map)\n",
    "\n",
    "    #Hidden point Removal\n",
    "    if Dbug==True:\n",
    "        o3d.visualization.draw_geometries([average_ptcloud,mesh], window_name=\"05_Filtered Pointcloud: Hidden point removal\", point_show_normal=True, zoom=zoom_def, front=front_def, lookat=lookat_def, up=up_def)\n",
    "\n",
    "    average_ptcloud = average_ptcloud.voxel_down_sample(voxel_size=spacing)\n",
    "\n",
    "    #Downsample point cloud\n",
    "    if Dbug==True:\n",
    "        o3d.visualization.draw_geometries([average_ptcloud,mesh], window_name=\"06_Filtered Pointcloud: Downsample the pointcloud\", point_show_normal=True, zoom=zoom_def, front=front_def, lookat=lookat_def, up=up_def)\n",
    "\n",
    "    #Estimate Normals\n",
    "    average_ptcloud.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.06, max_nn=30)) #radius in meters\n",
    "    average_ptcloud.orient_normals_towards_camera_location(camera_location=[0, 0, 0])\n",
    "\n",
    "    #Re = average_ptcloud.get_rotation_matrix_from_xyz((np.pi, 0 , 0))\n",
    "    #filtered_Pt_Cloud = average_ptcloud.rotate(Re, center=(0,0,0))\n",
    "\n",
    "    filtered_Pt_Cloud = average_ptcloud\n",
    "\n",
    "    if (Hide_prev==False or Dbug==True):\n",
    "        o3d.visualization.draw_geometries([filtered_Pt_Cloud,mesh], window_name=\"07_Filtered Pointcloud: Estimate surface normals\", point_show_normal=True, zoom=zoom_def, front=front_def, lookat=lookat_def, up=up_def)\n",
    "\n",
    "    return(filtered_Pt_Cloud)\n",
    "\n",
    "\n",
    "def New_world_coordinates(world_coords, eef_link, new_z_offset=0.0, old_z_offset=0.0,  coord_skip=1):\n",
    "    \n",
    "    z_offset = new_z_offset#old_z_offset+new_z_offset\n",
    "\n",
    "    new_world_coordinates_store=[]\n",
    "\n",
    "    for id_x in range(0,len(world_coords),coord_skip):\n",
    "        transform_world_plane = world_coords[id_x]\n",
    "        KDL_original_plane_frame = PyKDL.Frame(PyKDL.Rotation.Quaternion(transform_world_plane[3],\n",
    "                                                                         transform_world_plane[4], \n",
    "                                                                         transform_world_plane[5], \n",
    "                                                                         transform_world_plane[6]),\n",
    "                                               PyKDL.Vector(transform_world_plane[0], \n",
    "                                                            transform_world_plane[1], \n",
    "                                                            transform_world_plane[2]))\n",
    "\n",
    "        trans_x,trans_y,trans_z = KDL_original_plane_frame * PyKDL.Vector(0, 0, z_offset) #Add offset\n",
    "        KDL_original_plane_frame.p = PyKDL.Vector(trans_x,trans_y,trans_z) #update original plane frame to new location\n",
    "\n",
    "        #KDL_flip_frame = PyKDL.Frame(PyKDL.Rotation.RPY(np.pi, 0.,np.pi), PyKDL.Vector(0, 0, 0)) #not required here\n",
    "        KDL_final_frame = KDL_original_plane_frame #* KDL_flip_frame\n",
    "        KDL_trans = KDL_final_frame.p\n",
    "        KDL_ROT_quat = KDL_final_frame.M.GetQuaternion() \n",
    "        final_coordinates = [KDL_trans[0], KDL_trans[1], KDL_trans[2], KDL_ROT_quat[0], KDL_ROT_quat[1], \n",
    "                                                                       KDL_ROT_quat[2], KDL_ROT_quat[3]]\n",
    "\n",
    "        new_world_coordinates_store.append(final_coordinates)\n",
    "    #world_coords = np.append(world_coords, np.array(new_world_coordinates),axis=0)\n",
    "    \n",
    "    return new_world_coordinates_store\n",
    "\n",
    "\n",
    "print(\"Loaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156af4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "front_def = [ -0.38077889171563734, 0.78942164088651434, -0.48147783804018851 ]\n",
    "lookat_def = [ 0.16328584993371112, 0.10901604638723184, 0.39735867391549773 ]\n",
    "up_def = [ 0.17393478184042019, -0.45025906577602964, -0.87579304938588232 ]\n",
    "saved_path = \"VI_appdata/Saved_coordinates/\"\n",
    "\n",
    "pose_list = ['initial_coordinates_down_med', 'initial_coordinates_down_high', 'initial_coordinates_front_low',\n",
    "             'initial_coordinates_front_med', 'initial_coordinates_left_origin_low', 'initial_coordinates_left_origin_med',\n",
    "             'initial_coordinates_left_extended_low', 'initial_coordinates_left_extended_med', 'initial_coordinates_right_origin_low',\n",
    "             'initial_coordinates_right_origin_med', 'initial_coordinates_right_extended_low', 'initial_coordinates_right_extended_med']\n",
    "\n",
    "pose_list_joint = ['initial_coordinates_down_med_joint', 'initial_coordinates_down_high_joint', 'initial_coordinates_front_low_joint',\n",
    "                   'initial_coordinates_front_med_joint', 'initial_coordinates_left_origin_low_joint', 'initial_coordinates_left_origin_med_joint',\n",
    "                   'initial_coordinates_left_extended_low_joint', 'initial_coordinates_left_extended_med_joint', 'initial_coordinates_right_origin_low_joint',\n",
    "                   'initial_coordinates_right_origin_med_joint', 'initial_coordinates_right_extended_low_joint','initial_coordinates_right_extended_med_joint']\n",
    "\n",
    "config = ConfigParser() #recreate the object\n",
    "file_path = 'VI_appdata/'\n",
    "file_name = 'config.ini'\n",
    "\n",
    "while True:\n",
    "    if len(config.read(file_path+file_name)) < 1:\n",
    "        print(\"File not Found! Creating file with default parameters.\")\n",
    "\n",
    "        config.add_section('Settings')\n",
    "        config.set('Settings', 'samples', '1')\n",
    "        config.set('Settings', 'spacing', '0.01')\n",
    "        config.set('Settings', 'offset_y', '0.13')\n",
    "        config.set('Settings', 'offset_z', '0.0')\n",
    "        config.set('Settings', 'trim_base', '0.05')\n",
    "        config.set('Settings', 'manual_offset', '0.0')\n",
    "        config.set('Settings', 'Cluster_centered', 'True')\n",
    "        config.set('Settings', 'Cluster_idx', '0')\n",
    "        config.set('Settings', 'Cluster_discard', '0')\n",
    "        config.set('Settings', 'eps', '0.05')\n",
    "        config.set('Settings', 'min_points', '10')\n",
    "        config.set('Settings', 'Cluster_trim', '0.01')\n",
    "        config.set('Settings', 'TGT_coord_Samples', '3')\n",
    "        config.set('Settings', 'TGT_final_trim', '0.8')\n",
    "        config.set('Settings', 'TGT_reverse', 'True')\n",
    "        config.set('Settings', 'TGT_preview', 'True')\n",
    "        config.set('Settings', 'z_offset', '0.3')\n",
    "        config.set('Settings', 'coord_skip', '0')\n",
    "        config.set('Settings', 'TGT_motion_delay', '0.1')\n",
    "        config.set('Settings', 'TGT_save', 'True')\n",
    "        config.set('Settings', 'Dbug', 'False')\n",
    "        \n",
    "        \n",
    "        config.add_section('Init_Pose')\n",
    "        config.set('Init_Pose', 'initial_coordinates_front_low', str([0.397980905857042, 0.027217939895356813, 0.18229966557867178, \n",
    "                             0.719466879923975, -0.024833366401559, 0.6938126371395357, 0.019358128812197253]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_front_low_joint', str([-0.03308832927721994, -0.03018116998842668, 0.2330358247909432, \n",
    "                           -3.067160927725503, -2.877206619976536, 1.7093383191263651, -2.3699487627687947]))\n",
    "\n",
    "        config.set('Init_Pose', 'initial_coordinates_front_med', str([0.40482032529532164, 0.026194852526629283, 0.39109200963985485, \n",
    "                     0.7260836395583325, -0.022024302679397548, 0.6869470017604175, 0.020525477572626547]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_front_med_joint', str([-2.85595247676397, 0.8446004103871667, 2.8969771730651814, \n",
    "                       -2.935194399235205, -2.7707237618641196, 2.598331237598268, -2.8520272715670796]))\n",
    "        \n",
    "        config.set('Init_Pose', 'initial_coordinates_down_med', str([0.3057885688125996, 1.3924967197681087e-05, 0.4832398935268236, \n",
    "                   0.9999795762494257, 0.0001837540182692045, -0.0063807165029802415, 0.0003158724238107869]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_down_med_joint', str([0.00015612302097078867, -0.7820471788872219, 0.00021312723955091428, \n",
    "                     -2.3608742714695437, -0.00048321686683028275, 1.5660659497089506, 0.7853428543922201]))\n",
    "        \n",
    "        config.set('Init_Pose', 'initial_coordinates_down_high', str([0.4073103269798378,-1.4228208118709305e-05,0.7305284183578298,\n",
    "                       0.9999928346346129,-0.00048259177856538034,-0.003741879327895847,0.00031003822734821697]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_down_high_joint', str([-0.0004353885679213576, -0.09060550395190248, 0.0006182921638773209, \n",
    "                       -1.0642032332881817, -0.0006107609171950301, 0.9526048542598877, 0.7866203388740391]))\n",
    "        \n",
    "        config.set('Init_Pose', 'initial_coordinates_right_extended_low', str([0.303905123995592, 0.432574462138798, 0.14745536781503069, \n",
    "                        0.49793866097971806, -0.5190453811419719, 0.5022512997938495, 0.4799923062636517]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_right_extended_low_joint', str([-1.3627551805652836, -1.665272628644563, 1.8213776531030774, \n",
    "                      -0.9998667790998539, 0.23454549403950065, 0.8435528353614163, 2.7865978631457864]))\n",
    "        \n",
    "        config.set('Init_Pose', 'initial_coordinates_right_extended_med', str([0.2946072656492903, 0.42412609694782166, 0.3812023180158996, \n",
    "                      0.5004812310890651, -0.5145842693664336, 0.500097519321071, 0.48438005555255736]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_right_extended_med_joint', str([-1.2149762059636426, -1.4147605703375774, 1.630446034507517, \n",
    "                        -1.220881668558492, -0.12494140705733248, 0.8627764897864765, 2.414921812055187]))\n",
    "        \n",
    "        config.set('Init_Pose', 'initial_coordinates_right_origin_low', str([0.304617061088216, 0.010824979104373134, 0.13103384627481848, \n",
    "                            0.5000567302260833, -0.5176586342440617, 0.5011957042311564, 0.4803911645819538]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_right_origin_low_joint', str([-0.8306507813405739, -1.6702893075232446, 2.0899260568853126, \n",
    "                          -2.583962115788799, 0.4729478447971518, 1.9204627252998598, 2.5709161872287396]))\n",
    "        \n",
    "        config.set('Init_Pose', 'initial_coordinates_right_origin_med', str([0.2950873959916672, 0.0022689810690858375, 0.35247625585972037, \n",
    "                        0.5000080875838175, -0.517773630947132, 0.4994838572729616, 0.4820977657802621]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_right_origin_med_joint', str([-0.7394367859002831, -1.7502600075394135, 1.545832156050504, \n",
    "                      -2.7715569703412393, 0.1468177821017873, 1.9215750098383229, 2.189953048092672]))\n",
    "        \n",
    "        config.set('Init_Pose', 'initial_coordinates_left_extended_low', str([0.31155232781852343, -0.4086689597065088, 0.13700900414256567, \n",
    "                 -0.5010520177929303, -0.50991813124275, -0.48424832821784847, 0.5044144441961924]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_left_extended_low_joint', str([1.4792665598288135, -1.3786874126536794, -2.2556703813351007, \n",
    "                       -1.1207441668097236, 0.06761726972025528, 0.9208591206339669, -1.436089059953261]))\n",
    "        \n",
    "        config.set('Init_Pose', 'initial_coordinates_left_extended_med', str([0.31388297259319375, -0.4034255830492924, 0.3812481778815888, \n",
    "                     -0.5007903951112147, -0.5087092508711633, -0.48435410833506043, 0.5057914352590425]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_left_extended_med_joint', str([1.3489994479032257, -1.0385404174043078, -2.0826207583573364, \n",
    "                           -1.2522584530530603, 0.4164006949380532, 0.807743989710545, -1.132394918608119]))\n",
    "        \n",
    "        config.set('Init_Pose', 'initial_coordinates_left_origin_low', str([0.30019161622355806, -0.008566905843574349, 0.13068973171451095, \n",
    "                   -0.5008108668868128, -0.5113460029542676, -0.4841846837677913, 0.5032682514081904]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_left_origin_low_joint', str([1.1857468951962424, -1.0613242297651801, -2.0859292543370067, \n",
    "                     -2.593607189178292, 0.18790388228584032, 1.9826879664409294, -1.5356077559260912]))\n",
    "        \n",
    "        config.set('Init_Pose', 'initial_coordinates_left_origin_med', str([0.3022296225047282, -0.0016561879639682836, 0.3924491069637494, \n",
    "                   -0.5001942516935315, -0.511437879038984, -0.4833357967164821, 0.5046023326039006]))\n",
    "        config.set('Init_Pose', 'initial_coordinates_left_origin_med_joint', str([0.6729239245732437, -1.070449681957646, -1.2528592387187087, \n",
    "                 -2.6905143631133868, 0.5376461765737943, 1.757936868031745, -1.0937173345324362]))\n",
    "\n",
    "        # save to a file\n",
    "        with open(file_path+file_name, 'w') as configfile:\n",
    "            config.write(configfile)\n",
    "        \n",
    "        config = ConfigParser() #recreate the object\n",
    "        config.read(file_path+file_name) #Read the created file\n",
    "    else:\n",
    "        #Load all variables\n",
    "        samples = max(config.getint('Settings', 'samples'),1)\n",
    "        spacing = max(config.getfloat('Settings', 'spacing'),0)\n",
    "        offset_y = config.getfloat('Settings', 'offset_y')\n",
    "        offset_z = config.getfloat('Settings', 'offset_z')\n",
    "        trim_base = config.getfloat('Settings', 'trim_base')\n",
    "        manual_offset = config.getfloat('Settings', 'manual_offset')\n",
    "        Cluster_centered = config.getboolean('Settings', 'Cluster_centered')\n",
    "        Cluster_idx = config.getint('Settings', 'Cluster_idx')\n",
    "        Cluster_discard = config.getint('Settings', 'Cluster_discard')\n",
    "        eps = config.getfloat('Settings', 'eps')\n",
    "        min_points = config.getint('Settings', 'min_points')\n",
    "        Cluster_trim = config.getfloat('Settings', 'Cluster_trim')\n",
    "        TGT_coord_Samples = max(config.getint('Settings', 'TGT_coord_Samples'),3)\n",
    "        TGT_final_trim = config.getfloat('Settings', 'TGT_final_trim')\n",
    "        TGT_reverse = config.getboolean('Settings', 'TGT_reverse')\n",
    "        TGT_preview = config.getboolean('Settings', 'TGT_preview')\n",
    "        z_offset = config.getfloat('Settings', 'z_offset')\n",
    "        coord_skip = max(config.getint('Settings', 'coord_skip'),0)+1 #+1 to match the for loop's skip method.\n",
    "        TGT_motion_delay = config.getfloat('Settings', 'TGT_motion_delay')\n",
    "        TGT_save = config.getboolean('Settings', 'TGT_save')\n",
    "        Dbug = config.getboolean('Settings', 'Dbug')\n",
    "\n",
    "        init_data = [samples,spacing,offset_y,offset_z,trim_base,manual_offset,Cluster_centered,Cluster_idx,\n",
    "                 Cluster_discard,eps,min_points,Cluster_trim,TGT_coord_Samples,TGT_final_trim,TGT_reverse,\n",
    "                 TGT_preview,z_offset,coord_skip-1,TGT_motion_delay,TGT_save,Dbug] #-1 to display real meaning in settings gui\n",
    "\n",
    "        Front_data = Front_gui() # Call Front end GUI to select running mode.\n",
    "        \n",
    "        if Front_data == -1:\n",
    "            print(\"Exiting Program!\")\n",
    "            break\n",
    "\n",
    "#REPLAY MODE =====================================================================================================            \n",
    "#REPLAY MODE =====================================================================================================            \n",
    "        elif Front_data == 0:\n",
    "            print(\"Run in Replay mode\")\n",
    "            file_path='/'\n",
    "            X_offset=0.0 \n",
    "            Y_offset=0.0\n",
    "            Z_offset=0.0\n",
    "            \n",
    "            while True:\n",
    "                file_path, X_offset, Y_offset, Z_offset, TGT_save, OK_flag = Replay_gui(file_path, X_offset, Y_offset, Z_offset, TGT_save)\n",
    "                \n",
    "                if OK_flag == 0: #Preview\n",
    "                    print(\"Load coordinates, Add offsets and publish to Rviz and return to GUI\")\n",
    "                    \n",
    "                    with open(file_path, 'rb') as f:\n",
    "                        world_coords = np.load(f)\n",
    "                    del f\n",
    "\n",
    "                    world_coords[:,0:1] += X_offset\n",
    "                    world_coords[:,1:2] += Y_offset\n",
    "                    \n",
    "                    eef_link = move_group.get_end_effector_link()\n",
    "                    cam_tgt, eef_tgt = Generate_final_coordinates(world_coords, Z_offset+z_offset, eef_link, coord_skip=1)\n",
    "                    Publish_coordinates(cam_tgt, \"world\", 'Camera_Target', static = False)\n",
    "                    #Publish_coordinates(eef_tgt, \"world\", 'EEF_Target', static = False)\n",
    "                    #Publish_coordinates(world_coords,'world','plane', static = False)\n",
    "\n",
    "                    \n",
    "                elif OK_flag == 1: #OK\n",
    "                    print(\"Load coordinates, Add offsets and publish to Rviz and run and break out\")\n",
    "                    \n",
    "                    with open(file_path, 'rb') as f:\n",
    "                        world_coords = np.load(f)\n",
    "                    del f\n",
    "\n",
    "                    world_coords[:,0:1] += X_offset\n",
    "                    world_coords[:,1:2] += Y_offset\n",
    "                    \n",
    "                    \n",
    "                    eef_link = move_group.get_end_effector_link()\n",
    "                    cam_tgt, eef_tgt = Generate_final_coordinates(world_coords, Z_offset+z_offset, eef_link, coord_skip=1)\n",
    "\n",
    "                    if TGT_preview == True:\n",
    "                        Publish_coordinates(cam_tgt, \"world\", 'Camera_Target', static = False)\n",
    "                        #Publish_coordinates(eef_tgt, \"world\", 'EEF_Target', static = False)\n",
    "\n",
    "                    for id_x in range(0,len(eef_tgt)):  \n",
    "\n",
    "                        Publish_coordinates([cam_tgt[id_x]], \"world\", 'Camera_Target', static = False)   \n",
    "                        #Publish_coordinates([eef_tgt[id_x]], \"world\", 'EEF_Target', static = False)\n",
    "\n",
    "                        ## Move Robot to TARGET\n",
    "                        go_to_coord_goal(move_group, eef_tgt[id_x]) #pass values to function to make robot move in cartesian space. \n",
    "                        print(\"Moving to Target:\",id_x+1)\n",
    "                        time.sleep(TGT_motion_delay)\n",
    "\n",
    "\n",
    "                    world_coords_new = New_world_coordinates(world_coords, eef_link, new_z_offset=Z_offset, old_z_offset=z_offset, coord_skip=1)\n",
    "                    \n",
    "                    #Save Coordinates\n",
    "                    if TGT_save == True:\n",
    "                        print(\"Open Save Dialogue\")\n",
    "\n",
    "                        file_path, Save_mode = Save_gui()\n",
    "                        if Save_mode == -1:\n",
    "                            break\n",
    "                        elif Save_mode == 0: #Create_New_file\n",
    "                            print(\"Creating New file\")\n",
    "                            if len(sorted(glob.iglob(saved_path+\"saved_*\"))) > 0:\n",
    "                                last_file = sorted(glob.iglob(saved_path+\"saved_*\"))[-1].strip('.npy')\n",
    "                                file_num = int(last_file[len(last_file) - 3:])+1 #new file number\n",
    "                                file_num_str = \"{0:0=3d}\".format(file_num)\n",
    "                                coord_filename = \"saved_\" + file_num_str\n",
    "                            else:\n",
    "                                coord_filename = \"saved_000\"\n",
    "                            coord_path = saved_path+coord_filename+\".npy\"\n",
    "\n",
    "                            with open(coord_path, 'wb') as f:\n",
    "                                np.save(f, world_coords_new)\n",
    "\n",
    "                            break\n",
    "\n",
    "                        elif Save_mode == 1: #Overwrite default saved file of manual mode\n",
    "                            print(\"Overwriting saved.npy file\")\n",
    "\n",
    "                            coord_filename = \"saved\"\n",
    "                            coord_path = saved_path+coord_filename+\".npy\"\n",
    "\n",
    "                            with open(coord_path, 'wb') as f:\n",
    "                                np.save(f, world_coords_new)\n",
    "\n",
    "                            break\n",
    "\n",
    "                        elif Save_mode == 2: #Append coordinates to selected file\n",
    "                            print(\"Append to selected file\")\n",
    "\n",
    "                            #Load old coordinates\n",
    "                            with open(file_path, 'rb') as f:\n",
    "                                old_world_coords = np.load(f)\n",
    "                                \n",
    "                            del f\n",
    "                            \n",
    "                            #Append New coordinates to old coordinates\n",
    "                            world_coords_save = np.append(old_world_coords, world_coords_new, axis=0)\n",
    "                            print(world_coords_save)\n",
    "                            #Save coordinates to same file\n",
    "                            with open(file_path, 'wb') as g:\n",
    "                                np.save(g, world_coords_save)                    \n",
    "\n",
    "                            break\n",
    "\n",
    "                    \n",
    "                elif OK_flag == -1: #EXIT\n",
    "                    print(\"Exit Replay mode\")\n",
    "                    break\n",
    "                \n",
    "            break\n",
    "\n",
    "#MANUAL MODE =====================================================================================================\n",
    "#MANUAL MODE =====================================================================================================\n",
    "        elif Front_data == 1:\n",
    "            print(\"Run in Manual mode\")  #Move robot to a specific pose.                        \n",
    "            pose_idx, manual_offset, TGT_save,Exit_flag = Manual_gui(manual_offset, TGT_save) # Call Manual mode GUI.\n",
    "            \n",
    "            if Exit_flag==1:\n",
    "                print(\"Exiting Manual mode\")\n",
    "                Front_data = -1\n",
    "                break\n",
    "            \n",
    "            \n",
    "            #selected_pose = eval(config.get('Init_Pose', pose_list[pose_idx])) #eval will revert char string to whatever it was.\n",
    "            #go_to_coord_goal(move_group, selected_pose) #pass values to function to make robot move in cartesian space. \n",
    "            selected_pose_joint = eval(config.get('Init_Pose', pose_list_joint[pose_idx])) #eval will revert char string to whatever it was.\n",
    "            print(\"Moving to initial position\")\n",
    "            go_to_joint_state(move_group, selected_pose_joint)\n",
    "            \n",
    "            #Fetch filtered PC.\n",
    "            filtered_Pt_Cloud = Load_PC(samples,offset_y,offset_z,spacing,trim_base,Hide_prev=False,Dbug=Dbug)  \n",
    "            \n",
    "            #Clustering\n",
    "            clouds = Cluster_Point_Cloud(filtered_Pt_Cloud, eps=eps, min_points=min_points) \n",
    "\n",
    "            result,selected_motion = Cluster_selection_gui(clouds) #Will present a GUI to select all relevant pointclouds\n",
    "            #o3d.visualization.draw_geometries([result, mesh], point_show_normal=True)\n",
    "\n",
    "            result = cropped_PC(result, spacing, Cluster_trim, X=selected_motion, idx = Cluster_idx, centered = Cluster_centered, resample = True)\n",
    "            if (Hide_prev==False or Dbug==True):\n",
    "                zoom_def = 2.0\n",
    "                mesh_big = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.3,origin=[0, 0, 0])\n",
    "                o3d.visualization.draw_geometries([result,mesh_big], window_name=\"08_Filtered Pointcloud: Object profile generated\", point_show_normal=True, zoom=zoom_def, \n",
    "                                                  front=front_def, lookat=lookat_def, up=up_def)\n",
    "                       \n",
    "            #Coordinate Generation\n",
    "            _, world_coords = filter_generate_coordinates(result, spacing, sample=TGT_coord_Samples, silent=False, remove_close_targets=True)\n",
    "            print(\"Total coordinates:\",len(world_coords))\n",
    "            if TGT_reverse == True:\n",
    "                world_coords = world_coords[::-1]  #reverse\n",
    "\n",
    "            eef_link = move_group.get_end_effector_link()  # get current eef link either link8 if panda_arm selected \n",
    "                                                           # or hand_tcp if panda_manipulator is selected.\n",
    "            cam_tgt, eef_tgt = Generate_final_coordinates(world_coords, z_offset, eef_link, coord_skip=coord_skip)\n",
    "\n",
    "            #Coordinate PREVIEW\n",
    "            if TGT_preview == True:\n",
    "                Publish_coordinates(cam_tgt, \"world\", 'Camera_Target', static = False)\n",
    "                #Publish_coordinates(eef_tgt, \"world\", 'EEF_Target', static = False)\n",
    "\n",
    "            #ROBOT MOTION\n",
    "            for id_x in range(0,len(eef_tgt)):  \n",
    "\n",
    "                Publish_coordinates([cam_tgt[id_x]], \"world\", 'Camera_Target', static = False)   \n",
    "                #Publish_coordinates([eef_tgt[id_x]], \"world\", 'EEF_Target', static = False)\n",
    "\n",
    "                ## Move Robot to TARGET\n",
    "                go_to_coord_goal(move_group, eef_tgt[id_x]) #pass values to function to make robot move in cartesian space. \n",
    "                print(\"Moving to Target:\",id_x+1)\n",
    "                time.sleep(TGT_motion_delay)\n",
    "\n",
    "            #Save Coordinates\n",
    "            if TGT_save == True:\n",
    "                print(\"Open Save Dialogue\")\n",
    "                \n",
    "                file_path, Save_mode = Save_gui()\n",
    "                if Save_mode == -1:\n",
    "                    break\n",
    "                elif Save_mode == 0: #Create_New_file\n",
    "                    print(\"Creating New file\")\n",
    "                    if len(sorted(glob.iglob(saved_path+\"saved_manual_*\"))) > 0:\n",
    "                        last_file = sorted(glob.iglob(saved_path+\"saved_manual_*\"))[-1].strip('.npy')\n",
    "                        file_num = int(last_file[len(last_file) - 3:])+1 #new file number\n",
    "                        file_num_str = \"{0:0=3d}\".format(file_num)\n",
    "                        coord_filename = \"saved_manual_\" + file_num_str\n",
    "                    else:\n",
    "                        coord_filename = \"saved_manual_000\"\n",
    "                    coord_path = saved_path+coord_filename+\".npy\"\n",
    "                    \n",
    "                    with open(coord_path, 'wb') as f:\n",
    "                        np.save(f, world_coords)\n",
    "                        \n",
    "                    break\n",
    "                    \n",
    "                elif Save_mode == 1: #Overwrite default saved file of manual mode\n",
    "                    print(\"Overwriting saved_manual.npy file\")\n",
    "                    \n",
    "                    coord_filename = \"saved_manual\"\n",
    "                    coord_path = saved_path+coord_filename+\".npy\"\n",
    "\n",
    "                    with open(coord_path, 'wb') as f:\n",
    "                        np.save(f, world_coords)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "                \n",
    "                elif Save_mode == 2: #Append coordinates to selected file\n",
    "                    print(\"Append to selected file\")\n",
    "                    \n",
    "                    #Load old coordinates\n",
    "                    with open(file_path, 'rb') as f:\n",
    "                        old_world_coords = np.load(f)\n",
    "                        \n",
    "                    #Append New coordinates to old coordinates\n",
    "                    world_coords_save = np.append(old_world_coords, world_coords,axis=0)\n",
    "                    \n",
    "                    #Save coordinates to same file\n",
    "                    with open(file_path, 'wb') as f:\n",
    "                        np.save(f, world_coords_save)                    \n",
    "                        \n",
    "                        \n",
    "                    break\n",
    "                \n",
    "            break\n",
    "\n",
    "#AUTO MODE =====================================================================================================\n",
    "#AUTO MODE =====================================================================================================\n",
    "        elif Front_data == 2:\n",
    "            print(\"Run in Auto mode\")\n",
    "            world_coords_total = np.array([[0.,0.,0.,0.,0.,0.,0.]])\n",
    "            last = []\n",
    "\n",
    "            pose_idx, manual_offset, cluster_number, selected_motion, TGT_save, Auto_loop, Hide_prev,Exit_flag = Auto_gui(manual_offset, TGT_save)\n",
    "\n",
    "            if Exit_flag==1:\n",
    "                print(\"Exiting Auto mode\")\n",
    "                Front_data = -1\n",
    "                break\n",
    "            #selected_pose = eval(config.get('Init_Pose', pose_list[pose_idx])) #eval will revert char string to whatever it was.\n",
    "            #go_to_coord_goal(move_group, selected_pose) #pass values to function to make robot move in cartesian space. \n",
    "            selected_pose_joint = eval(config.get('Init_Pose', pose_list_joint[pose_idx])) #eval will revert char string to whatever it was.\n",
    "            print(\"Moving to initial position\")\n",
    "            go_to_joint_state(move_group, selected_pose_joint)\n",
    "            \n",
    "            \n",
    "            for i in range(Auto_loop):\n",
    "            \n",
    "                filtered_Pt_Cloud = Load_PC(samples,offset_y,offset_z,spacing,trim_base,Hide_prev)  #Fetch filtered PC.\n",
    "            \n",
    "                #Clustering\n",
    "                clouds = Cluster_Point_Cloud(filtered_Pt_Cloud, eps=eps, min_points=min_points) \n",
    "                \n",
    "                if Hide_prev == False:\n",
    "                    result,selected_motion = Cluster_selection_gui(clouds) #Will present a GUI to select all relevant pointclouds\n",
    "                    #o3d.visualization.draw_geometries([result, mesh], point_show_normal=True)\n",
    "                    result = cropped_PC(result, spacing, Cluster_trim, X=selected_motion, idx = Cluster_idx, centered = Cluster_centered, resample = True)\n",
    "                else:\n",
    "                    result = cropped_PC(clouds[cluster_number], spacing, Cluster_trim, X=selected_motion, idx = Cluster_idx, centered = Cluster_centered, resample = True)\n",
    "                \n",
    "                if (Hide_prev==False or Dbug==True):\n",
    "                    zoom_def = 2.0\n",
    "                    mesh_big = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.3,origin=[0, 0, 0])\n",
    "                    o3d.visualization.draw_geometries([result,mesh_big], window_name=\"08_Filtered Pointcloud: Object profile generated\", point_show_normal=True, zoom=zoom_def, \n",
    "                                                          front=front_def, lookat=lookat_def, up=up_def)\n",
    "                        \n",
    "\n",
    "                _, world_coords = filter_generate_coordinates(result, spacing, sample=TGT_coord_Samples, silent=False, remove_close_targets=True)\n",
    "                print(\"Total coordinates:\",len(world_coords))\n",
    "                \n",
    "                if TGT_reverse == True:\n",
    "                    world_coords = world_coords[::-1]  #reverse\n",
    "                    \n",
    "                if len(last)>0:  #if list is not empty\n",
    "                    idx = np.argmin(np.linalg.norm(last - world_coords[:,:3], axis=1)) #give the index of value where it is most similar\n",
    "                    world_coords = world_coords[idx:]\n",
    "\n",
    "                last = world_coords[-1,:3]\n",
    "\n",
    "                world_coords_total = np.append(world_coords_total,world_coords,axis=0)\n",
    "\n",
    "\n",
    "                eef_link = move_group.get_end_effector_link()\n",
    "                cam_tgt, eef_tgt = Generate_final_coordinates(world_coords, z_offset, eef_link, coord_skip=coord_skip)\n",
    "\n",
    "\n",
    "                if TGT_preview == True:\n",
    "                    Publish_coordinates(cam_tgt, \"world\", 'Camera_Target', static = False)\n",
    "                    #Publish_coordinates(eef_tgt, \"world\", 'EEF_Target', static = False)\n",
    "\n",
    "\n",
    "                for id_x in range(0,len(eef_tgt)):  \n",
    "\n",
    "                    Publish_coordinates([cam_tgt[id_x]], \"world\", 'Camera_Target', static = False)   \n",
    "                    #Publish_coordinates([eef_tgt[id_x]], \"world\", 'EEF_Target', static = False)\n",
    "\n",
    "                    ## Move Robot to TARGET\n",
    "                    go_to_coord_goal(move_group, eef_tgt[id_x]) #pass values to function to make robot move in cartesian space. \n",
    "                    print(\"Moving to Target:\",id_x+1)\n",
    "                    time.sleep(TGT_motion_delay)\n",
    "\n",
    "            world_coords_total = np.delete(world_coords_total, 0, axis=0)\n",
    "            \n",
    "\n",
    "            #Save Coordinates\n",
    "            if TGT_save == True:\n",
    "                print(\"Open Save Dialogue\")\n",
    "                \n",
    "                file_path, Save_mode = Save_gui()\n",
    "                if Save_mode == -1:\n",
    "                    print(\"Not Saving\")\n",
    "                    break\n",
    "                elif Save_mode == 0: #Create_New_file\n",
    "                    print(\"Creating New file\")\n",
    "                    if len(sorted(glob.iglob(saved_path+\"saved_Auto_*\"))) > 0:\n",
    "                        last_file = sorted(glob.iglob(saved_path+\"saved_Auto_*\"))[-1].strip('.npy')\n",
    "                        file_num = int(last_file[len(last_file) - 3:])+1 #new file number\n",
    "                        file_num_str = \"{0:0=3d}\".format(file_num)\n",
    "                        coord_filename = \"saved_Auto_\" + file_num_str\n",
    "                    else:\n",
    "                        coord_filename = \"saved_Auto_000\"\n",
    "                    coord_path = saved_path+coord_filename+\".npy\"\n",
    "                    \n",
    "                    with open(coord_path, 'wb') as f:\n",
    "                        np.save(f, world_coords_total)\n",
    "                        \n",
    "                    break\n",
    "                    \n",
    "                elif Save_mode == 1: #Overwrite default saved file of manual mode\n",
    "                    print(\"Overwriting saved_Auto.npy file\")\n",
    "                    \n",
    "                    coord_filename = \"saved_Auto\"\n",
    "                    coord_path = saved_path+coord_filename+\".npy\"\n",
    "\n",
    "                    with open(coord_path, 'wb') as f:\n",
    "                        np.save(f, world_coords_total)\n",
    "                    \n",
    "                    \n",
    "                    break\n",
    "                \n",
    "                elif Save_mode == 2: #Append coordinates to selected file\n",
    "                    print(\"Append to selected file\")\n",
    "                    \n",
    "                    #Load old coordinates\n",
    "                    with open(file_path, 'rb') as f:\n",
    "                        old_world_coords = np.load(f)\n",
    "                        \n",
    "                    #Append New coordinates to old coordinates\n",
    "                    world_coords_save = np.append(old_world_coords, world_coords_total,axis=0)\n",
    "                    \n",
    "                    #Save coordinates to same file\n",
    "                    with open(file_path, 'wb') as f:\n",
    "                        np.save(f, world_coords_save)                    \n",
    "                        \n",
    "                    break\n",
    "                \n",
    "            break\n",
    "\n",
    "\n",
    "#SETTINGS MODE =====================================================================================================\n",
    "#SETTINGS MODE =====================================================================================================\n",
    "        elif Front_data == 3:\n",
    "            #Open settings\n",
    "            Settings_data = Setting_gui(init_data)\n",
    "\n",
    "            status_flag = Settings_data[0]\n",
    "\n",
    "            if status_flag == 1:  #update values and save new config as string\n",
    "\n",
    "                config.set('Settings', 'samples', str(Settings_data[1]))\n",
    "                config.set('Settings', 'spacing', str(Settings_data[2]))\n",
    "                config.set('Settings', 'offset_y', str(Settings_data[3]))\n",
    "                config.set('Settings', 'offset_z', str(Settings_data[4]))\n",
    "                config.set('Settings', 'trim_base', str(Settings_data[5]))\n",
    "                config.set('Settings', 'manual_offset', str(Settings_data[6]))\n",
    "                config.set('Settings', 'Cluster_centered', str(Settings_data[7]))\n",
    "                config.set('Settings', 'Cluster_idx', str(Settings_data[8]))\n",
    "                config.set('Settings', 'Cluster_discard', str(Settings_data[9]))\n",
    "                config.set('Settings', 'eps', str(Settings_data[10]))\n",
    "                config.set('Settings', 'min_points', str(Settings_data[11]))\n",
    "                config.set('Settings', 'Cluster_trim', str(Settings_data[12]))\n",
    "                config.set('Settings', 'TGT_coord_Samples', str(Settings_data[13]))\n",
    "                config.set('Settings', 'TGT_final_trim', str(Settings_data[14]))\n",
    "                config.set('Settings', 'TGT_reverse', str(Settings_data[15]))\n",
    "                config.set('Settings', 'TGT_preview', str(Settings_data[16]))\n",
    "                config.set('Settings', 'z_offset', str(Settings_data[17]))\n",
    "                config.set('Settings', 'coord_skip', str(Settings_data[18]))\n",
    "                config.set('Settings', 'TGT_motion_delay', str(Settings_data[19]))\n",
    "                config.set('Settings', 'TGT_save', str(Settings_data[20]))\n",
    "                config.set('Settings', 'Dbug', str(Settings_data[21]))\n",
    "\n",
    "                # save to a file\n",
    "                with open(file_path+file_name, 'w') as configfile:\n",
    "                    config.write(configfile)\n",
    "\n",
    "#print(samples,spacing,offset_y,offset_z,trim_base,manual_offset,Cluster_centered,Cluster_idx,\n",
    "#      Cluster_discard,eps,min_points,Cluster_trim,TGT_coord_Samples,TGT_final_trim,TGT_reverse,\n",
    "#      TGT_preview,z_offset,coord_skip,TGT_motion_delay,TGT_save,Dbug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_group.get_current_pose()\n",
    "#go_to_joint_state(move_group, selected_pose_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105b51d7",
   "metadata": {},
   "source": [
    "### Clustering of points in Point cloud\n",
    "ref: http://www.open3d.org/docs/release/tutorial/geometry/pointcloud.html#DBSCAN-clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e32e8",
   "metadata": {},
   "source": [
    "### Crop point cloud to get a points in a single line in X or Y axis, \n",
    "*Use idx to give offset else use centered to get the points from center of the object*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf797ad",
   "metadata": {},
   "source": [
    "### This will generate and boradcast all points in pointcloud to tf2 or tf2_static topic, visualize using Rviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f63a8",
   "metadata": {},
   "source": [
    "## Publish Targets for Preview"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9852f98f",
   "metadata": {},
   "source": [
    "#Publish_coordinates(world_coords,'world','plane', static = False)\n",
    "for i in range (len(world_coords)):\n",
    "    Publish_coordinates([world_coords[i]],'world','plane', static = False)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43269c",
   "metadata": {},
   "source": [
    "## Robot Motion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14866dcf",
   "metadata": {},
   "source": [
    "aa = move_group.get_current_pose()\n",
    "print([aa.pose.position.x,\n",
    " aa.pose.position.y,\n",
    " aa.pose.position.z,\n",
    " aa.pose.orientation.x,\n",
    " aa.pose.orientation.y,\n",
    " aa.pose.orientation.z,\n",
    " aa.pose.orientation.w])\n",
    "print()\n",
    "print(move_group.get_current_joint_values())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea0e864f",
   "metadata": {},
   "source": [
    "print(\"============ Printing robot current Joint values\") #O/P: current joint values of the end-effector\n",
    "#print(move_group.get_current_joint_values())\n",
    "print(\"In Degrees: \", np.degrees( move_group.get_current_joint_values() ) ) #O/P joint angles in degrees\n",
    "print(\"\")\n",
    "\n",
    "print(\"============ Printing robot current pose\") #O/P will be XYZ and xyz w  positions and orientations of the robot.\n",
    "print(move_group.get_current_pose())\n",
    "print(\"\")\n",
    "\n",
    "print(\"============ Printing robot current RPY\") #O/P wil be orientation of end-effector in RPY (Radians)\n",
    "#print(move_group.get_current_rpy())\n",
    "print(\"RPY In Degrees: \", np.degrees( move_group.get_current_rpy() ) )\n",
    "\n",
    "eef_link = move_group.get_end_effector_link()\n",
    "print(\"============ End effector link: %s\" % eef_link) #O/P: ============ End effector link: panda_link8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
